{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd4a8ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /Users/adminericcheng/.pyenv/versions/3.12.4/envs/hw5/lib/python3.12/site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /Users/adminericcheng/.pyenv/versions/3.12.4/envs/hw5/lib/python3.12/site-packages (from pandas) (2.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/adminericcheng/.pyenv/versions/3.12.4/envs/hw5/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/adminericcheng/.pyenv/versions/3.12.4/envs/hw5/lib/python3.12/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/adminericcheng/.pyenv/versions/3.12.4/envs/hw5/lib/python3.12/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/adminericcheng/.pyenv/versions/3.12.4/envs/hw5/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: numpy in /Users/adminericcheng/.pyenv/versions/3.12.4/envs/hw5/lib/python3.12/site-packages (2.2.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: matplotlib in /Users/adminericcheng/.pyenv/versions/3.12.4/envs/hw5/lib/python3.12/site-packages (3.10.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/adminericcheng/.pyenv/versions/3.12.4/envs/hw5/lib/python3.12/site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/adminericcheng/.pyenv/versions/3.12.4/envs/hw5/lib/python3.12/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/adminericcheng/.pyenv/versions/3.12.4/envs/hw5/lib/python3.12/site-packages (from matplotlib) (4.57.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/adminericcheng/.pyenv/versions/3.12.4/envs/hw5/lib/python3.12/site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: numpy>=1.23 in /Users/adminericcheng/.pyenv/versions/3.12.4/envs/hw5/lib/python3.12/site-packages (from matplotlib) (2.2.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/adminericcheng/.pyenv/versions/3.12.4/envs/hw5/lib/python3.12/site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in /Users/adminericcheng/.pyenv/versions/3.12.4/envs/hw5/lib/python3.12/site-packages (from matplotlib) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/adminericcheng/.pyenv/versions/3.12.4/envs/hw5/lib/python3.12/site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/adminericcheng/.pyenv/versions/3.12.4/envs/hw5/lib/python3.12/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/adminericcheng/.pyenv/versions/3.12.4/envs/hw5/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Collecting scikit-learn\n",
      "  Using cached scikit_learn-1.6.1-cp312-cp312-macosx_12_0_arm64.whl.metadata (31 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /Users/adminericcheng/.pyenv/versions/3.12.4/envs/hw5/lib/python3.12/site-packages (from scikit-learn) (2.2.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /Users/adminericcheng/.pyenv/versions/3.12.4/envs/hw5/lib/python3.12/site-packages (from scikit-learn) (1.15.2)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Using cached threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Using cached scikit_learn-1.6.1-cp312-cp312-macosx_12_0_arm64.whl (11.2 MB)\n",
      "Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Using cached threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, joblib, scikit-learn\n",
      "Successfully installed joblib-1.4.2 scikit-learn-1.6.1 threadpoolctl-3.6.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: xgboost in /Users/adminericcheng/.pyenv/versions/3.12.4/envs/hw5/lib/python3.12/site-packages (3.0.0)\n",
      "Requirement already satisfied: numpy in /Users/adminericcheng/.pyenv/versions/3.12.4/envs/hw5/lib/python3.12/site-packages (from xgboost) (2.2.0)\n",
      "Requirement already satisfied: scipy in /Users/adminericcheng/.pyenv/versions/3.12.4/envs/hw5/lib/python3.12/site-packages (from xgboost) (1.15.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "!pip install numpy\n",
    "!pip install matplotlib\n",
    "!pip install scikit-learn\n",
    "!pip install xgboost\n",
    "!pip install lightgbm\n",
    "!pip install catboost\n",
    "!pip install optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "281e1fcb",
   "metadata": {},
   "source": [
    "Load data and split into training+testing data randomly (80/20 split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed3469c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before mapping: Team1 Result\n",
      "victory    1652\n",
      "defeat     1437\n",
      "draw          3\n",
      "Name: count, dtype: int64\n",
      "After mapping: Team1 Result\n",
      "1    1652\n",
      "0    1437\n",
      "Name: count, dtype: int64\n",
      "Remaining rows: 3089\n",
      "['Mode', 'Map', 'Team1 Result', 'Brawler 1', 'Brawler 2', 'Brawler 3', 'Brawler 4', 'Brawler 5', 'Brawler 6']\n",
      "        Mode             Map  Team1 Result Brawler 1 Brawler 2 Brawler 3  \\\n",
      "0      heist  Bridge Too Far             1     Piper     Amber     Brock   \n",
      "1      heist  Bridge Too Far             0     Piper     Amber     Brock   \n",
      "2  brawlBall    Pinhole Punt             1      Carl       Lou       Stu   \n",
      "3  brawlBall    Pinhole Punt             1      Carl       Lou       Stu   \n",
      "4      heist        Pit Stop             0     Griff  El Primo     Mr. P   \n",
      "\n",
      "  Brawler 4 Brawler 5 Brawler 6  \n",
      "0      Carl       Eve      Colt  \n",
      "1      Carl       Eve      Colt  \n",
      "2      Hank      Crow    Buster  \n",
      "3      Hank      Crow    Buster  \n",
      "4      Gray      Nita      Buzz  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 1. Load the CSV again\n",
    "df = pd.read_csv('data/brawl_scrim_040325.csv').iloc[:, 2:]\n",
    "\n",
    "# 2. Drop the specified columns\n",
    "drop_cols = [\n",
    "    'Day', 'Hour',\n",
    "    'P1', 'P2', 'P3', 'P4', 'P5', 'P6',\n",
    "    'Tag 1', 'Tag 2', 'Tag 3', 'Tag 4', 'Tag 5', 'Tag 6',\n",
    "    'Type', 'ISO', 'team 1', 'team 2'\n",
    "]\n",
    "df = df.drop(drop_cols, axis=1, errors='ignore')\n",
    "\n",
    "# 3. Extract 'ID' so it's not used as a feature or target\n",
    "ids = df.pop('ID')\n",
    "\n",
    "# 4. Inspect 'Team1 Result' distribution\n",
    "print(\"Before mapping:\", df['Team1 Result'].value_counts(dropna=False))\n",
    "\n",
    "# 5. Drop the rare 'draw' rows\n",
    "df = df[df['Team1 Result'] != 'draw']\n",
    "\n",
    "# 6. Map 'victory'->1, 'defeat'->0\n",
    "df['Team1 Result'] = df['Team1 Result'].map({'victory': 1, 'defeat': 0})\n",
    "\n",
    "# 7. Confirm everything\n",
    "print(\"After mapping:\", df['Team1 Result'].value_counts())\n",
    "print(\"Remaining rows:\", len(df))\n",
    "\n",
    "# Split train/test data\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Check remaining columns\n",
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b67bbf",
   "metadata": {},
   "source": [
    "Now trying xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbab09c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before encoding\n",
      "         Mode             Map  Team1 Result Brawler 1 Brawler 2 Brawler 3  \\\n",
      "2582   bounty         Hideout             1       Gus      Carl   Melodie   \n",
      "168   gemGrab       Last Stop             0       Ash        Bo     Amber   \n",
      "2584   bounty         Hideout             1     Piper     Byron      Hank   \n",
      "2135  gemGrab  Hard Rock Mine             1      Carl      Hank       Max   \n",
      "1956  gemGrab       Last Stop             0     8-Bit     Mr. P      Carl   \n",
      "\n",
      "     Brawler 4 Brawler 5 Brawler 6  \n",
      "2582       Kit      Lola     Ollie  \n",
      "168        Bea    Meeple     Ollie  \n",
      "2584     Mandy       Lou       Max  \n",
      "2135     Frank       Bea    Meeple  \n",
      "1956   Melodie       Stu     Amber  \n",
      "After encoding\n",
      "         Mode             Map  Team1 Result Brawler 1 Brawler 2 Brawler 3  \\\n",
      "2582   bounty         Hideout             1       Gus      Carl   Melodie   \n",
      "168   gemGrab       Last Stop             0       Ash        Bo     Amber   \n",
      "2584   bounty         Hideout             1     Piper     Byron      Hank   \n",
      "2135  gemGrab  Hard Rock Mine             1      Carl      Hank       Max   \n",
      "1956  gemGrab       Last Stop             0     8-Bit     Mr. P      Carl   \n",
      "\n",
      "     Brawler 4 Brawler 5 Brawler 6  \n",
      "2582       Kit      Lola     Ollie  \n",
      "168        Bea    Meeple     Ollie  \n",
      "2584     Mandy       Lou       Max  \n",
      "2135     Frank       Bea    Meeple  \n",
      "1956   Melodie       Stu     Amber  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adminericcheng/.pyenv/versions/3.12.4/envs/hw5/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [00:48:18] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/adminericcheng/.pyenv/versions/3.12.4/envs/hw5/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [00:48:18] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/adminericcheng/.pyenv/versions/3.12.4/envs/hw5/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [00:48:18] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/adminericcheng/.pyenv/versions/3.12.4/envs/hw5/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [00:48:18] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/adminericcheng/.pyenv/versions/3.12.4/envs/hw5/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [00:48:18] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/adminericcheng/.pyenv/versions/3.12.4/envs/hw5/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [00:48:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/adminericcheng/.pyenv/versions/3.12.4/envs/hw5/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [00:48:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/adminericcheng/.pyenv/versions/3.12.4/envs/hw5/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [00:48:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/adminericcheng/.pyenv/versions/3.12.4/envs/hw5/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [00:48:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/adminericcheng/.pyenv/versions/3.12.4/envs/hw5/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [00:48:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/adminericcheng/.pyenv/versions/3.12.4/envs/hw5/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [00:48:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/adminericcheng/.pyenv/versions/3.12.4/envs/hw5/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [00:48:21] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/adminericcheng/.pyenv/versions/3.12.4/envs/hw5/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [00:48:21] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/adminericcheng/.pyenv/versions/3.12.4/envs/hw5/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [00:48:21] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/adminericcheng/.pyenv/versions/3.12.4/envs/hw5/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [00:48:21] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/adminericcheng/.pyenv/versions/3.12.4/envs/hw5/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [00:48:22] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/adminericcheng/.pyenv/versions/3.12.4/envs/hw5/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [00:48:22] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/adminericcheng/.pyenv/versions/3.12.4/envs/hw5/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [00:48:22] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/adminericcheng/.pyenv/versions/3.12.4/envs/hw5/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [00:48:22] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/adminericcheng/.pyenv/versions/3.12.4/envs/hw5/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [00:48:22] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/adminericcheng/.pyenv/versions/3.12.4/envs/hw5/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [00:48:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/adminericcheng/.pyenv/versions/3.12.4/envs/hw5/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [00:48:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/adminericcheng/.pyenv/versions/3.12.4/envs/hw5/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [00:48:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/adminericcheng/.pyenv/versions/3.12.4/envs/hw5/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [00:48:24] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/adminericcheng/.pyenv/versions/3.12.4/envs/hw5/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [00:48:24] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/adminericcheng/.pyenv/versions/3.12.4/envs/hw5/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [00:48:24] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/adminericcheng/.pyenv/versions/3.12.4/envs/hw5/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [00:48:25] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/adminericcheng/.pyenv/versions/3.12.4/envs/hw5/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [00:48:25] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/adminericcheng/.pyenv/versions/3.12.4/envs/hw5/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [00:48:25] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/adminericcheng/.pyenv/versions/3.12.4/envs/hw5/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [00:48:25] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/adminericcheng/.pyenv/versions/3.12.4/envs/hw5/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [00:48:25] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/adminericcheng/.pyenv/versions/3.12.4/envs/hw5/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [00:48:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/adminericcheng/.pyenv/versions/3.12.4/envs/hw5/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [00:48:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/adminericcheng/.pyenv/versions/3.12.4/envs/hw5/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [00:48:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/adminericcheng/.pyenv/versions/3.12.4/envs/hw5/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [00:48:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/adminericcheng/.pyenv/versions/3.12.4/envs/hw5/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [00:48:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/adminericcheng/.pyenv/versions/3.12.4/envs/hw5/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [00:48:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/adminericcheng/.pyenv/versions/3.12.4/envs/hw5/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [00:48:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/adminericcheng/.pyenv/versions/3.12.4/envs/hw5/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [00:48:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/adminericcheng/.pyenv/versions/3.12.4/envs/hw5/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [00:48:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/adminericcheng/.pyenv/versions/3.12.4/envs/hw5/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [00:48:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/adminericcheng/.pyenv/versions/3.12.4/envs/hw5/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [00:48:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/adminericcheng/.pyenv/versions/3.12.4/envs/hw5/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [00:48:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/adminericcheng/.pyenv/versions/3.12.4/envs/hw5/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [00:48:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/adminericcheng/.pyenv/versions/3.12.4/envs/hw5/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [00:48:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/adminericcheng/.pyenv/versions/3.12.4/envs/hw5/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [00:48:30] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/adminericcheng/.pyenv/versions/3.12.4/envs/hw5/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [00:48:30] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/adminericcheng/.pyenv/versions/3.12.4/envs/hw5/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [00:48:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/adminericcheng/.pyenv/versions/3.12.4/envs/hw5/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [00:48:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/adminericcheng/.pyenv/versions/3.12.4/envs/hw5/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [00:48:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/adminericcheng/.pyenv/versions/3.12.4/envs/hw5/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [00:48:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/adminericcheng/.pyenv/versions/3.12.4/envs/hw5/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [00:48:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/adminericcheng/.pyenv/versions/3.12.4/envs/hw5/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [00:48:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/adminericcheng/.pyenv/versions/3.12.4/envs/hw5/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [00:48:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/adminericcheng/.pyenv/versions/3.12.4/envs/hw5/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [00:48:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/adminericcheng/.pyenv/versions/3.12.4/envs/hw5/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [00:48:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/adminericcheng/.pyenv/versions/3.12.4/envs/hw5/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [00:48:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/adminericcheng/.pyenv/versions/3.12.4/envs/hw5/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [00:48:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/adminericcheng/.pyenv/versions/3.12.4/envs/hw5/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [00:48:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/adminericcheng/.pyenv/versions/3.12.4/envs/hw5/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [00:48:34] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/adminericcheng/.pyenv/versions/3.12.4/envs/hw5/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [00:48:34] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/adminericcheng/.pyenv/versions/3.12.4/envs/hw5/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [00:48:35] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/adminericcheng/.pyenv/versions/3.12.4/envs/hw5/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [00:48:35] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/adminericcheng/.pyenv/versions/3.12.4/envs/hw5/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [00:48:35] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/adminericcheng/.pyenv/versions/3.12.4/envs/hw5/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [00:48:35] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/adminericcheng/.pyenv/versions/3.12.4/envs/hw5/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [00:48:35] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/adminericcheng/.pyenv/versions/3.12.4/envs/hw5/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [00:48:35] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/adminericcheng/.pyenv/versions/3.12.4/envs/hw5/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [00:48:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/adminericcheng/.pyenv/versions/3.12.4/envs/hw5/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [00:48:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/adminericcheng/.pyenv/versions/3.12.4/envs/hw5/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [00:48:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/adminericcheng/.pyenv/versions/3.12.4/envs/hw5/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [00:48:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/adminericcheng/.pyenv/versions/3.12.4/envs/hw5/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [00:48:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   colsample_bytree  learning_rate  max_depth  n_estimators  subsample  \\\n",
      "0               0.8            0.1          7           200        0.8   \n",
      "1               0.8            0.1          5           100        0.8   \n",
      "2               0.8            0.1          7           100        0.8   \n",
      "3               1.0            0.2          3           200        0.8   \n",
      "4               1.0            0.1          3           100        0.8   \n",
      "5               0.8            0.1          5           200        0.8   \n",
      "6               1.0            0.2          5           100        0.8   \n",
      "7               1.0            0.2          3           100        1.0   \n",
      "8               1.0            0.1          5           100        0.8   \n",
      "9               1.0            0.1          3           200        0.8   \n",
      "\n",
      "   accuracy  \n",
      "0  0.580906  \n",
      "1  0.579288  \n",
      "2  0.577670  \n",
      "3  0.574434  \n",
      "4  0.572816  \n",
      "5  0.571197  \n",
      "6  0.569579  \n",
      "7  0.566343  \n",
      "8  0.566343  \n",
      "9  0.566343  \n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Encoding text fields\n",
    "print(\"Before encoding\")\n",
    "print(train_df.head())\n",
    "\n",
    "# # list out the text columns\n",
    "cat_cols = ['Mode','Map','Brawler 1','Brawler 2','Brawler 3','Brawler 4','Brawler 5','Brawler 6']\n",
    "for c in cat_cols:\n",
    "    train_df[c] = train_df[c].astype('category')\n",
    "    test_df[c]  = test_df[c].astype('category')\n",
    "\n",
    "# # fit a LabelEncoder for each column on training data\n",
    "# encoders = {}\n",
    "# for c in cat_cols:\n",
    "#     le = LabelEncoder()\n",
    "#     # .astype(str) in case there are any NaNs\n",
    "#     train_df[c] = le.fit_transform(train_df[c].astype(str))\n",
    "#     test_df[c]  = le.transform(test_df[c].astype(str))\n",
    "#     encoders[c] = le\n",
    "print(\"After encoding\")\n",
    "print(train_df.head())\n",
    "\n",
    "# 1. Separate features/target\n",
    "X_train = train_df.drop('Team1 Result', axis=1)\n",
    "y_train = train_df['Team1 Result']\n",
    "X_test  = test_df.drop('Team1 Result', axis=1)\n",
    "y_test  = test_df['Team1 Result']\n",
    "\n",
    "# 2. Define a hyperparameter grid\n",
    "param_grid = {\n",
    "    'max_depth':        [3, 5, 7],\n",
    "    'learning_rate':    [0.01, 0.1, 0.2],\n",
    "    'n_estimators':     [100, 200],\n",
    "    'subsample':        [0.8, 1.0],\n",
    "    'colsample_bytree': [0.8, 1.0],\n",
    "}\n",
    "\n",
    "# 3. Loop over all combinations, train & evaluate\n",
    "results = []\n",
    "for params in ParameterGrid(param_grid):\n",
    "    model = XGBClassifier(\n",
    "        tree_method='hist',\n",
    "        enable_categorical=True,\n",
    "        eval_metric='logloss',\n",
    "        n_jobs=-1,\n",
    "        **params\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "    acc = accuracy_score(y_test, preds)\n",
    "    results.append({**params, 'accuracy': acc})\n",
    "\n",
    "# 4. Collect and sort results\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df = results_df.sort_values('accuracy', ascending=False).reset_index(drop=True)\n",
    "\n",
    "# 5. Inspect top performers\n",
    "print(results_df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351491b5",
   "metadata": {},
   "source": [
    "Increasing data set size by permuting the order of brawlers on each team! 36x increase\n",
    "We do this to training/test data separately to avoid data leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51af3e40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original train rows: 2471, augmented: 88956\n",
      "Original test  rows: 618,  augmented: 22248\n",
      "        Mode      Map  Team1 Result Brawler 1 Brawler 2 Brawler 3 Brawler 4  \\\n",
      "2582  bounty  Hideout             1       Gus      Carl   Melodie       Kit   \n",
      "2582  bounty  Hideout             1       Gus      Carl   Melodie       Kit   \n",
      "2582  bounty  Hideout             1       Gus      Carl   Melodie      Lola   \n",
      "2582  bounty  Hideout             1       Gus      Carl   Melodie      Lola   \n",
      "2582  bounty  Hideout             1       Gus      Carl   Melodie     Ollie   \n",
      "2582  bounty  Hideout             1       Gus      Carl   Melodie     Ollie   \n",
      "2582  bounty  Hideout             1       Gus   Melodie      Carl       Kit   \n",
      "2582  bounty  Hideout             1       Gus   Melodie      Carl       Kit   \n",
      "2582  bounty  Hideout             1       Gus   Melodie      Carl      Lola   \n",
      "2582  bounty  Hideout             1       Gus   Melodie      Carl      Lola   \n",
      "\n",
      "     Brawler 5 Brawler 6  \n",
      "2582      Lola     Ollie  \n",
      "2582     Ollie      Lola  \n",
      "2582       Kit     Ollie  \n",
      "2582     Ollie       Kit  \n",
      "2582       Kit      Lola  \n",
      "2582      Lola       Kit  \n",
      "2582      Lola     Ollie  \n",
      "2582     Ollie      Lola  \n",
      "2582       Kit     Ollie  \n",
      "2582     Ollie       Kit  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import itertools\n",
    "\n",
    "def augment_by_swapping(df):\n",
    "    \"\"\"\n",
    "    For each row in df, generate all permutations of Brawler 1–3 and\n",
    "    Brawler 4–6, and return a new DataFrame with every permuted copy.\n",
    "    \"\"\"\n",
    "    team1_cols = ['Brawler 1', 'Brawler 2', 'Brawler 3']\n",
    "    team2_cols = ['Brawler 4', 'Brawler 5', 'Brawler 6']\n",
    "    \n",
    "    rows = []\n",
    "    for _, row in df.iterrows():\n",
    "        t1 = tuple(row[c] for c in team1_cols)\n",
    "        t2 = tuple(row[c] for c in team2_cols)\n",
    "        \n",
    "        for perm1 in itertools.permutations(t1):\n",
    "            for perm2 in itertools.permutations(t2):\n",
    "                new_row = row.copy()\n",
    "                # reassign permuted values\n",
    "                for i, c in enumerate(team1_cols):\n",
    "                    new_row[c] = perm1[i]\n",
    "                for i, c in enumerate(team2_cols):\n",
    "                    new_row[c] = perm2[i]\n",
    "                rows.append(new_row)\n",
    "    \n",
    "    aug_df = pd.DataFrame(rows)\n",
    "    # if any duplicate rows (e.g. brawlers repeated), drop exact duplicates:\n",
    "    # aug_df = aug_df.drop_duplicates().reset_index(drop=True)\n",
    "    return aug_df\n",
    "\n",
    "# ▶ Apply separately to train and test\n",
    "train_aug = augment_by_swapping(train_df)\n",
    "test_aug  = augment_by_swapping(test_df)\n",
    "\n",
    "print(f\"Original train rows: {len(train_df)}, augmented: {len(train_aug)}\")\n",
    "print(f\"Original test  rows: {len(test_df)},  augmented: {len(test_aug)}\")\n",
    "print(train_aug.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bcacff3",
   "metadata": {},
   "source": [
    "Augmenting the data again by inverting the result and putting team2's brawler picks in team1's position. 2x the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2c11d8b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 88956 → 177912 rows\n",
      "Test:  22248  → 44496 rows\n",
      "     Mode      Map  Team1 Result Brawler 1 Brawler 2 Brawler 3 Brawler 4  \\\n",
      "0  bounty  Hideout             1       Gus      Carl   Melodie       Kit   \n",
      "1  bounty  Hideout             1       Gus      Carl   Melodie       Kit   \n",
      "2  bounty  Hideout             1       Gus      Carl   Melodie      Lola   \n",
      "3  bounty  Hideout             1       Gus      Carl   Melodie      Lola   \n",
      "4  bounty  Hideout             1       Gus      Carl   Melodie     Ollie   \n",
      "\n",
      "  Brawler 5 Brawler 6  \n",
      "0      Lola     Ollie  \n",
      "1     Ollie      Lola  \n",
      "2       Kit     Ollie  \n",
      "3     Ollie       Kit  \n",
      "4       Kit      Lola  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def invert_and_swap(df):\n",
    "    \"\"\"\n",
    "    For each row in df, create a copy where:\n",
    "    - Team1 and Team2 brawlers are swapped\n",
    "    - Team1 Result is inverted (1->0, 0->1)\n",
    "    \"\"\"\n",
    "    team1 = ['Brawler 1','Brawler 2','Brawler 3']\n",
    "    team2 = ['Brawler 4','Brawler 5','Brawler 6']\n",
    "    \n",
    "    swapped = df.copy()\n",
    "    swapped[team1] = df[team2].values\n",
    "    swapped[team2] = df[team1].values\n",
    "    swapped['Team1 Result'] = 1 - df['Team1 Result']\n",
    "    return swapped\n",
    "\n",
    "# Generate the swapped/inverted copies\n",
    "train_swapped = invert_and_swap(train_aug)\n",
    "test_swapped  = invert_and_swap(test_aug)\n",
    "\n",
    "# Concatenate to double the size\n",
    "train_final = pd.concat([train_aug,    train_swapped], ignore_index=True)\n",
    "test_final  = pd.concat([test_aug,     test_swapped],  ignore_index=True)\n",
    "\n",
    "print(f\"Train: {len(train_aug)} → {len(train_final)} rows\")\n",
    "print(f\"Test:  {len(test_aug)}  → {len(test_final)} rows\")\n",
    "\n",
    "print(train_final.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ca2a37",
   "metadata": {},
   "source": [
    "Rerunning on augmented data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bde896c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   colsample_bytree  learning_rate  max_depth  n_estimators  subsample  \\\n",
      "0               0.8           0.10          3           100        0.8   \n",
      "1               0.8           0.20          7           100        1.0   \n",
      "2               0.8           0.01          3           100        0.8   \n",
      "3               1.0           0.10          3           200        0.8   \n",
      "4               1.0           0.01          7           200        0.8   \n",
      "5               0.8           0.10          5           100        1.0   \n",
      "6               1.0           0.01          5           100        0.8   \n",
      "7               1.0           0.01          3           100        0.8   \n",
      "8               0.8           0.01          5           200        0.8   \n",
      "9               1.0           0.20          5           200        0.8   \n",
      "\n",
      "   accuracy  \n",
      "0  0.553398  \n",
      "1  0.548544  \n",
      "2  0.546926  \n",
      "3  0.543689  \n",
      "4  0.543689  \n",
      "5  0.543689  \n",
      "6  0.542071  \n",
      "7  0.542071  \n",
      "8  0.540453  \n",
      "9  0.540453  \n"
     ]
    }
   ],
   "source": [
    "cat_cols = ['Mode','Map','Brawler 1','Brawler 2','Brawler 3','Brawler 4','Brawler 5','Brawler 6']\n",
    "for c in cat_cols:\n",
    "    train_final[c] = train_df[c].astype('category')\n",
    "    test_df[c]  = test_df[c].astype('category')\n",
    "\n",
    "# 1. Separate features/target\n",
    "X_train = train_final.drop('Team1 Result', axis=1)\n",
    "y_train = train_final['Team1 Result']\n",
    "X_test  = test_df.drop('Team1 Result', axis=1)\n",
    "y_test  = test_df['Team1 Result']\n",
    "\n",
    "# 2. Define a hyperparameter grid\n",
    "param_grid = {\n",
    "    'max_depth':        [3, 5, 7],\n",
    "    'learning_rate':    [0.01, 0.1, 0.2],\n",
    "    'n_estimators':     [100, 200],\n",
    "    'subsample':        [0.8, 1.0],\n",
    "    'colsample_bytree': [0.8, 1.0],\n",
    "}\n",
    "\n",
    "# 3. Loop over all combinations, train & evaluate\n",
    "results = []\n",
    "for params in ParameterGrid(param_grid):\n",
    "    model = XGBClassifier(\n",
    "        tree_method='hist',\n",
    "        enable_categorical=True,\n",
    "        eval_metric='logloss',\n",
    "        n_jobs=-1,\n",
    "        **params\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "    acc = accuracy_score(y_test, preds)\n",
    "    results.append({**params, 'accuracy': acc})\n",
    "\n",
    "# 4. Collect and sort results\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df = results_df.sort_values('accuracy', ascending=False).reset_index(drop=True)\n",
    "\n",
    "# 5. Inspect top performers\n",
    "print(results_df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f471842",
   "metadata": {},
   "source": [
    "Redoing with unordered sets for the brawlers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d8133d95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before mapping: Team1 Result\n",
      "victory    1652\n",
      "defeat     1437\n",
      "draw          3\n",
      "Name: count, dtype: int64\n",
      "After mapping: Team1 Result\n",
      "1    1652\n",
      "0    1437\n",
      "Name: count, dtype: int64\n",
      "Remaining rows: 3089\n",
      "['Mode', 'Map', 'Team1 Result', 'Brawler 1', 'Brawler 2', 'Brawler 3', 'Brawler 4', 'Brawler 5', 'Brawler 6']\n",
      "Unordered-set XGBoost accuracy: 0.5938511326860841\n",
      "testing hyperparameter impact\n",
      "   colsample_bytree  learning_rate  max_depth  n_estimators  subsample  \\\n",
      "0               0.8            0.2          7           200        1.0   \n",
      "1               1.0            0.2          7           200        0.8   \n",
      "2               0.8            0.2          7           100        0.8   \n",
      "3               1.0            0.1          7           200        1.0   \n",
      "\n",
      "   accuracy  \n",
      "0  0.631068  \n",
      "1  0.622977  \n",
      "2  0.614887  \n",
      "3  0.613269  \n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "from pandas.errors import PerformanceWarning\n",
    "\n",
    "# turn off only the “highly fragmented” performance warnings\n",
    "warnings.filterwarnings('ignore', category=PerformanceWarning)\n",
    "\n",
    "# 1. Load the CSV again\n",
    "df = pd.read_csv('data/brawl_scrim_040325.csv').iloc[:, 2:]\n",
    "\n",
    "# 2. Drop the specified columns\n",
    "drop_cols = [\n",
    "    'Day', 'Hour',\n",
    "    'P1', 'P2', 'P3', 'P4', 'P5', 'P6',\n",
    "    'Tag 1', 'Tag 2', 'Tag 3', 'Tag 4', 'Tag 5', 'Tag 6',\n",
    "    'Type', 'ISO', 'team 1', 'team 2'\n",
    "]\n",
    "df = df.drop(drop_cols, axis=1, errors='ignore')\n",
    "\n",
    "# 3. Extract 'ID' so it's not used as a feature or target\n",
    "ids = df.pop('ID')\n",
    "\n",
    "# 4. Inspect 'Team1 Result' distribution\n",
    "print(\"Before mapping:\", df['Team1 Result'].value_counts(dropna=False))\n",
    "\n",
    "# 5. Drop the rare 'draw' rows\n",
    "df = df[df['Team1 Result'] != 'draw']\n",
    "\n",
    "# 6. Map 'victory'->1, 'defeat'->0\n",
    "df['Team1 Result'] = df['Team1 Result'].map({'victory': 1, 'defeat': 0})\n",
    "\n",
    "# 7. Confirm everything\n",
    "print(\"After mapping:\", df['Team1 Result'].value_counts())\n",
    "print(\"Remaining rows:\", len(df))\n",
    "\n",
    "# Split train/test data\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Check remaining columns\n",
    "print(df.columns.tolist())\n",
    "\n",
    "# --- after you've done train/test split ---\n",
    "\n",
    "# Define your slot columns\n",
    "team1 = ['Brawler 1','Brawler 2','Brawler 3']\n",
    "team2 = ['Brawler 4','Brawler 5','Brawler 6']\n",
    "\n",
    "# 1. Gather every unique brawler ID in train (so test uses the same set)\n",
    "all_brawlers = pd.unique(\n",
    "    pd.concat([train_df[c] for c in team1 + team2], ignore_index=True)\n",
    ")\n",
    "all_brawlers = sorted([b for b in all_brawlers if pd.notna(b)])  # drop NaNs\n",
    "\n",
    "# 2. One‑hot “does this team have brawler X?”\n",
    "for df_ in (train_df, test_df):\n",
    "    for b in all_brawlers:\n",
    "        df_[f'T1_has_{b}'] = df_[team1].isin([b]).any(axis=1).astype(int)\n",
    "        df_[f'T2_has_{b}'] = df_[team2].isin([b]).any(axis=1).astype(int)\n",
    "    # 3. drop the original slot columns\n",
    "    df_.drop(team1 + team2, axis=1, inplace=True)\n",
    "\n",
    "# 4. (Optional) convert Mode/Map to numeric codes\n",
    "for col in ['Mode','Map']:\n",
    "    train_df[col] = train_df[col].astype('category').cat.codes\n",
    "    test_df[col]  = test_df[col].astype('category').cat.codes\n",
    "\n",
    "# 5. Now you can fit XGBoost exactly as before:\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X_train = train_df.drop('Team1 Result', axis=1)\n",
    "y_train = train_df['Team1 Result']\n",
    "X_test  = test_df.drop('Team1 Result', axis=1)\n",
    "y_test  = test_df['Team1 Result']\n",
    "\n",
    "model = XGBClassifier(eval_metric='logloss', n_jobs=-1)\n",
    "model.fit(X_train, y_train)\n",
    "print(\"Unordered-set XGBoost accuracy:\", accuracy_score(y_test, model.predict(X_test)))\n",
    "\n",
    "print(\"testing hyperparameter impact\")\n",
    "# 3. Loop over all combinations, train & evaluate\n",
    "results = []\n",
    "for params in ParameterGrid(param_grid):\n",
    "    model = XGBClassifier(\n",
    "        tree_method='hist',\n",
    "        enable_categorical=True,\n",
    "        eval_metric='logloss',\n",
    "        n_jobs=-1,\n",
    "        **params\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "    acc = accuracy_score(y_test, preds)\n",
    "    results.append({**params, 'accuracy': acc})\n",
    "\n",
    "# 4. Collect and sort results\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df = results_df.sort_values('accuracy', ascending=False).reset_index(drop=True)\n",
    "\n",
    "# 5. Inspect top performers\n",
    "print(results_df.head(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "961687f3",
   "metadata": {},
   "source": [
    "testing if inverting label and swapping teams to double data helps.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "75db1167",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unordered-set XGBoost accuracy: 0.5792880258899676\n",
      "testing hyperparameter impact\n",
      "   colsample_bytree  learning_rate  max_depth  n_estimators  subsample  \\\n",
      "0               0.8            0.2          7           200        0.8   \n",
      "1               1.0            0.2          7           200        0.8   \n",
      "2               0.8            0.1          7           200        0.8   \n",
      "3               0.8            0.2          7           200        1.0   \n",
      "\n",
      "   accuracy  \n",
      "0  0.622977  \n",
      "1  0.616505  \n",
      "2  0.608414  \n",
      "3  0.606796  \n"
     ]
    }
   ],
   "source": [
    "def swap_teams_and_flip(df):\n",
    "    # assumes T1_has_X and T2_has_X features already exist for each brawler X\n",
    "    t1_cols = [c for c in df.columns if c.startswith('T1_has_')]\n",
    "    t2_cols = [c for c in df.columns if c.startswith('T2_has_')]\n",
    "    \n",
    "    swapped = df.copy()\n",
    "    swapped[t1_cols] = df[t2_cols].values\n",
    "    swapped[t2_cols] = df[t1_cols].values\n",
    "    swapped['Team1 Result'] = 1 - df['Team1 Result']\n",
    "    return swapped\n",
    "\n",
    "# Example usage on your training set:\n",
    "train_swapped = swap_teams_and_flip(train_df)\n",
    "X_aug = pd.concat([train_df, train_swapped], ignore_index=True)\n",
    "y_aug = X_aug.pop('Team1 Result')\n",
    "\n",
    "# Then retrain:\n",
    "model = XGBClassifier(eval_metric='logloss', n_jobs=-1)\n",
    "model.fit(X_aug, y_aug)\n",
    "print(\"Unordered-set XGBoost accuracy:\", accuracy_score(y_test, model.predict(X_test)))\n",
    "\n",
    "print(\"testing hyperparameter impact\")\n",
    "# 3. Loop over all combinations, train & evaluate\n",
    "results = []\n",
    "for params in ParameterGrid(param_grid):\n",
    "    model = XGBClassifier(\n",
    "        tree_method='hist',\n",
    "        enable_categorical=True,\n",
    "        eval_metric='logloss',\n",
    "        n_jobs=-1,\n",
    "        **params\n",
    "    )\n",
    "    model.fit(X_aug, y_aug)\n",
    "    preds = model.predict(X_test)\n",
    "    acc = accuracy_score(y_test, preds)\n",
    "    results.append({**params, 'accuracy': acc})\n",
    "\n",
    "# 4. Collect and sort results\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df = results_df.sort_values('accuracy', ascending=False).reset_index(drop=True)\n",
    "\n",
    "# 5. Inspect top performers\n",
    "print(results_df.head(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f9ac58",
   "metadata": {},
   "source": [
    "Gradient boosting models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8eaa5234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1315, number of negative: 1156\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010642 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 295\n",
      "[LightGBM] [Info] Number of data points in the train set: 2471, number of used features: 135\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532173 -> initscore=0.128871\n",
      "[LightGBM] [Info] Start training from score 0.128871\n",
      "LGBMClassifier 0.5970873786407767\n",
      "CatBoostClassifier 0.6148867313915858\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "lgb = LGBMClassifier(n_jobs=-1)\n",
    "cat = CatBoostClassifier(verbose=False)\n",
    "\n",
    "for model in (lgb, cat):\n",
    "    model.fit(X_train, y_train)\n",
    "    print(model.__class__.__name__,\n",
    "          accuracy_score(y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26b93d6",
   "metadata": {},
   "source": [
    "Random forest and histboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2dee8dee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier 0.6294498381877023\n",
      "HistGradientBoostingClassifier 0.5825242718446602\n",
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "Best params: {'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 30, 'bootstrap': True}\n",
      "Accuracy: 0.6456310679611651\n",
      "ROC AUC: 0.6506647517872794\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.56      0.59       281\n",
      "           1       0.66      0.72      0.69       337\n",
      "\n",
      "    accuracy                           0.65       618\n",
      "   macro avg       0.64      0.64      0.64       618\n",
      "weighted avg       0.64      0.65      0.64       618\n",
      "\n",
      "Confusion Matrix:\n",
      " [[157 124]\n",
      " [ 95 242]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, HistGradientBoostingClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "rf  = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "hgb = HistGradientBoostingClassifier()\n",
    "\n",
    "for model in (rf, hgb):\n",
    "    model.fit(X_train, y_train)\n",
    "    print(model.__class__.__name__,\n",
    "          accuracy_score(y_test, model.predict(X_test)))\n",
    "    \n",
    "# 2. Hyperparameter distribution (no 'auto')\n",
    "param_dist = {\n",
    "    'n_estimators': [5,10, 20, 50, 100, 200, 500],\n",
    "    'max_depth': [None, 5, 10, 20, 30],\n",
    "    'min_samples_split': [2, 3, 4, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4, 8],\n",
    "    'max_features': ['sqrt', 'log2', None],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "# 3. RandomizedSearchCV optimizing ROC AUC\n",
    "rf = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "rand_search = RandomizedSearchCV(\n",
    "    estimator=rf,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=30,\n",
    "    scoring='accuracy', # or 'roc_auc'\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    random_state=42\n",
    ")\n",
    "rand_search.fit(X_train, y_train)\n",
    "\n",
    "# 4. Evaluate on test\n",
    "best_rf = rand_search.best_estimator_\n",
    "y_pred = best_rf.predict(X_test)\n",
    "y_proba = best_rf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"Best params:\", rand_search.best_params_)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"ROC AUC:\", roc_auc_score(y_test, y_proba))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510a10b5",
   "metadata": {},
   "source": [
    "Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "eaac469f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression 0.5469255663430421\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg = LogisticRegression(solver='saga', max_iter=2000, n_jobs=-1)\n",
    "logreg.fit(X_train, y_train)\n",
    "print(\"LogisticRegression\", accuracy_score(y_test, logreg.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8393dc4c",
   "metadata": {},
   "source": [
    "Redoing but leaving in team names "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "964d7b06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Mode', 'Map', 'Team1 Result', 'Tag 1', 'Tag 2', 'Tag 3', 'Tag 4', 'Tag 5', 'Tag 6', 'Brawler 1', 'Brawler 2', 'Brawler 3', 'Brawler 4', 'Brawler 5', 'Brawler 6']\n",
      "Unordered-set XGBoost accuracy: 0.6488673139158576\n",
      "testing hyperparameter impact\n",
      "   colsample_bytree  learning_rate  max_depth  n_estimators  subsample  \\\n",
      "0               1.0            0.2          7           200        1.0   \n",
      "1               1.0            0.2          7           200        0.8   \n",
      "2               0.8            0.2          7           200        1.0   \n",
      "3               1.0            0.1          7           200        0.8   \n",
      "\n",
      "   accuracy  \n",
      "0  0.647249  \n",
      "1  0.645631  \n",
      "2  0.645631  \n",
      "3  0.644013  \n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "from pandas.errors import PerformanceWarning\n",
    "\n",
    "# turn off only the “highly fragmented” performance warnings\n",
    "warnings.filterwarnings('ignore', category=PerformanceWarning)\n",
    "\n",
    "# 1. Load the CSV again\n",
    "df = pd.read_csv('data/brawl_scrim_040325.csv').iloc[:, 2:]\n",
    "\n",
    "# 2. Drop the specified columns\n",
    "drop_cols = [\n",
    "    'Day', 'Hour',\n",
    "    'P1', 'P2', 'P3', 'P4', 'P5', 'P6',\n",
    "    'team 1', 'team 2',\n",
    "    # 'Tag 1', 'Tag 2', 'Tag 3', 'Tag 4', 'Tag 5', 'Tag 6',\n",
    "    'Type', 'ISO'\n",
    "]\n",
    "df = df.drop(drop_cols, axis=1, errors='ignore')\n",
    "\n",
    "# 3. Extract 'ID' so it's not used as a feature or target\n",
    "ids = df.pop('ID')\n",
    "\n",
    "# 5. Drop the rare 'draw' rows\n",
    "df = df[df['Team1 Result'] != 'draw']\n",
    "\n",
    "# 6. Map 'victory'->1, 'defeat'->0\n",
    "df['Team1 Result'] = df['Team1 Result'].map({'victory': 1, 'defeat': 0})\n",
    "\n",
    "# Split train/test data\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Check remaining columns\n",
    "print(df.columns.tolist())\n",
    "\n",
    "# --- after you've done train/test split ---\n",
    "\n",
    "# Define your slot columns\n",
    "team1 = ['Brawler 1','Brawler 2','Brawler 3']\n",
    "team2 = ['Brawler 4','Brawler 5','Brawler 6']\n",
    "\n",
    "# 1. Gather every unique brawler ID in train (so test uses the same set)\n",
    "all_brawlers = pd.unique(\n",
    "    pd.concat([train_df[c] for c in team1 + team2], ignore_index=True)\n",
    ")\n",
    "all_brawlers = sorted([b for b in all_brawlers if pd.notna(b)])  # drop NaNs\n",
    "\n",
    "# 2. One‑hot “does this team have brawler X?”\n",
    "for df_ in (train_df, test_df):\n",
    "    for b in all_brawlers:\n",
    "        df_[f'T1_has_{b}'] = df_[team1].isin([b]).any(axis=1).astype(int)\n",
    "        df_[f'T2_has_{b}'] = df_[team2].isin([b]).any(axis=1).astype(int)\n",
    "    # 3. drop the original slot columns\n",
    "    df_.drop(team1 + team2, axis=1, inplace=True)\n",
    "\n",
    "player1 = ['Tag 1', 'Tag 2', 'Tag 3']\n",
    "player2 = ['Tag 4', 'Tag 5', 'Tag 6']\n",
    "# 1. Gather every unique player ID in train (so test uses the same set)\n",
    "all_players = pd.unique(\n",
    "    pd.concat([train_df[c] for c in player1 + player2], ignore_index=True)\n",
    ")\n",
    "all_players = sorted([b for b in all_players if pd.notna(b)])  # drop NaNs\n",
    "# 2. One‑hot “does this team have player X?”\n",
    "for df_ in (train_df, test_df):\n",
    "    for b in all_players:\n",
    "        df_[f'T1_has_{b}'] = df_[player1].isin([b]).any(axis=1).astype(int)\n",
    "        df_[f'T2_has_{b}'] = df_[player2].isin([b]).any(axis=1).astype(int)\n",
    "    # 3. drop the original slot columns\n",
    "    df_.drop(player1 + player2, axis=1, inplace=True)\n",
    "\n",
    "# 4. (Optional) convert Mode/Map to numeric codes\n",
    "for col in ['Mode','Map']:\n",
    "    train_df[col] = train_df[col].astype('category').cat.codes\n",
    "    test_df[col]  = test_df[col].astype('category').cat.codes\n",
    "\n",
    "# 5. Now you can fit XGBoost exactly as before:\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X_train = train_df.drop('Team1 Result', axis=1)\n",
    "y_train = train_df['Team1 Result']\n",
    "X_test  = test_df.drop('Team1 Result', axis=1)\n",
    "y_test  = test_df['Team1 Result']\n",
    "\n",
    "model = XGBClassifier(eval_metric='logloss', n_jobs=-1)\n",
    "model.fit(X_train, y_train)\n",
    "print(\"Unordered-set XGBoost accuracy:\", accuracy_score(y_test, model.predict(X_test)))\n",
    "\n",
    "print(\"testing hyperparameter impact\")\n",
    "# 3. Loop over all combinations, train & evaluate\n",
    "results = []\n",
    "for params in ParameterGrid(param_grid):\n",
    "    model = XGBClassifier(\n",
    "        tree_method='hist',\n",
    "        enable_categorical=True,\n",
    "        eval_metric='logloss',\n",
    "        n_jobs=-1,\n",
    "        **params\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "    acc = accuracy_score(y_test, preds)\n",
    "    results.append({**params, 'accuracy': acc})\n",
    "\n",
    "# 4. Collect and sort results\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df = results_df.sort_values('accuracy', ascending=False).reset_index(drop=True)\n",
    "\n",
    "# 5. Inspect top performers\n",
    "print(results_df.head(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a11e7d",
   "metadata": {},
   "source": [
    "Random forest with teams "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2b4179b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier 0.6310679611650486\n",
      "HistGradientBoostingClassifier 0.6132686084142395\n",
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "Best params: {'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 30, 'bootstrap': True}\n",
      "Accuracy: 0.6407766990291263\n",
      "ROC AUC: 0.6713623451640496\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.50      0.56       281\n",
      "           1       0.64      0.76      0.70       337\n",
      "\n",
      "    accuracy                           0.64       618\n",
      "   macro avg       0.64      0.63      0.63       618\n",
      "weighted avg       0.64      0.64      0.63       618\n",
      "\n",
      "Confusion Matrix:\n",
      " [[140 141]\n",
      " [ 81 256]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, HistGradientBoostingClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "rf  = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "hgb = HistGradientBoostingClassifier()\n",
    "\n",
    "for model in (rf, hgb):\n",
    "    model.fit(X_train, y_train)\n",
    "    print(model.__class__.__name__,\n",
    "          accuracy_score(y_test, model.predict(X_test)))\n",
    "    \n",
    "# 2. Hyperparameter distribution (no 'auto')\n",
    "param_dist = {\n",
    "    'n_estimators': [5,10, 20, 50, 100, 200, 500],\n",
    "    'max_depth': [None, 5, 10, 20, 30],\n",
    "    'min_samples_split': [2, 3, 4, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4, 8],\n",
    "    'max_features': ['sqrt', 'log2', None],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "# 3. RandomizedSearchCV optimizing ROC AUC\n",
    "rf = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "rand_search = RandomizedSearchCV(\n",
    "    estimator=rf,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=30,\n",
    "    scoring='accuracy', # or 'roc_auc'\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    random_state=42\n",
    ")\n",
    "rand_search.fit(X_train, y_train)\n",
    "\n",
    "# 4. Evaluate on test\n",
    "best_rf = rand_search.best_estimator_\n",
    "y_pred = best_rf.predict(X_test)\n",
    "y_proba = best_rf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"Best params:\", rand_search.best_params_)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"ROC AUC:\", roc_auc_score(y_test, y_proba))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f476f2",
   "metadata": {},
   "source": [
    "Final for fun, testing no draft data at all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f21af9ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Mode', 'Map', 'Team1 Result', 'Tag 1', 'Tag 2', 'Tag 3', 'Tag 4', 'Tag 5', 'Tag 6']\n",
      "['Mode', 'Map', 'T1_has_#2028JJP8P', 'T2_has_#2028JJP8P', 'T1_has_#202GJJR28', 'T2_has_#202GJJR28', 'T1_has_#202GYRU0', 'T2_has_#202GYRU0', 'T1_has_#2092LGRLR', 'T2_has_#2092LGRLR', 'T1_has_#20C0LL00', 'T2_has_#20C0LL00', 'T1_has_#20JC8GJLQ', 'T2_has_#20JC8GJLQ', 'T1_has_#20JP809C2', 'T2_has_#20JP809C2', 'T1_has_#20JU9YJJP', 'T2_has_#20JU9YJJP', 'T1_has_#20L0C9GCP', 'T2_has_#20L0C9GCP', 'T1_has_#20L88L2J', 'T2_has_#20L88L2J', 'T1_has_#20PVYLJQG', 'T2_has_#20PVYLJQG', 'T1_has_#2208QGGGL', 'T2_has_#2208QGGGL', 'T1_has_#220PGLU02', 'T2_has_#220PGLU02', 'T1_has_#220UJU8P2', 'T2_has_#220UJU8P2', 'T1_has_#222R82RCU', 'T2_has_#222R82RCU', 'T1_has_#2282LR0YG', 'T2_has_#2282LR0YG', 'T1_has_#2288RRJJG', 'T2_has_#2288RRJJG', 'T1_has_#229CQLP0QV', 'T2_has_#229CQLP0QV', 'T1_has_#22CL00PG0', 'T2_has_#22CL00PG0', 'T1_has_#22JR2JLYC', 'T2_has_#22JR2JLYC', 'T1_has_#280RJ29R9', 'T2_has_#280RJ29R9', 'T1_has_#28CL0QVRQV', 'T2_has_#28CL0QVRQV', 'T1_has_#28LUY98', 'T2_has_#28LUY98', 'T1_has_#28PCVLJCL', 'T2_has_#28PCVLJCL', 'T1_has_#28PPLLJ8U', 'T2_has_#28PPLLJ8U', 'T1_has_#28PU0P9L0', 'T2_has_#28PU0P9L0', 'T1_has_#28Q8CQUCP', 'T2_has_#28Q8CQUCP', 'T1_has_#28RRQCQ9J', 'T2_has_#28RRQCQ9J', 'T1_has_#2909LRLU', 'T2_has_#2909LRLU', 'T1_has_#2920VCVJJ', 'T2_has_#2920VCVJJ', 'T1_has_#29G0CYLU9', 'T2_has_#29G0CYLU9', 'T1_has_#29JJ20UG', 'T2_has_#29JJ20UG', 'T1_has_#29P0GP8UC', 'T2_has_#29P0GP8UC', 'T1_has_#29P9J89CP', 'T2_has_#29P9J89CP', 'T1_has_#29Q2V0LGU', 'T2_has_#29Q2V0LGU', 'T1_has_#29QGPVP2V', 'T2_has_#29QGPVP2V', 'T1_has_#29RJQLQQU', 'T2_has_#29RJQLQQU', 'T1_has_#29U29P80R', 'T2_has_#29U29P80R', 'T1_has_#29UGLJV2G', 'T2_has_#29UGLJV2G', 'T1_has_#29VRJU08C', 'T2_has_#29VRJU08C', 'T1_has_#2C80JVR8C', 'T2_has_#2C80JVR8C', 'T1_has_#2CJ0RCJ', 'T2_has_#2CJ0RCJ', 'T1_has_#2CLR2YQY', 'T2_has_#2CLR2YQY', 'T1_has_#2CQ0U882Q', 'T2_has_#2CQ0U882Q', 'T1_has_#2CY80RQUY', 'T2_has_#2CY80RQUY', 'T1_has_#2G0RRLU2R', 'T2_has_#2G0RRLU2R', 'T1_has_#2G82CGU', 'T2_has_#2G82CGU', 'T1_has_#2GV90L8YP', 'T2_has_#2GV90L8YP', 'T1_has_#2GVY09J2', 'T2_has_#2GVY09J2', 'T1_has_#2GYQ0QL', 'T2_has_#2GYQ0QL', 'T1_has_#2J0G220PC', 'T2_has_#2J0G220PC', 'T1_has_#2J8V8L0V2', 'T2_has_#2J8V8L0V2', 'T1_has_#2JLVRQ9', 'T2_has_#2JLVRQ9', 'T1_has_#2JQU8JQ2G', 'T2_has_#2JQU8JQ2G', 'T1_has_#2L08U08RUQ', 'T2_has_#2L08U08RUQ', 'T1_has_#2L89R02JV', 'T2_has_#2L89R02JV', 'T1_has_#2LCU2QGRJY', 'T2_has_#2LCU2QGRJY', 'T1_has_#2LG8QJ9L', 'T2_has_#2LG8QJ9L', 'T1_has_#2LL892UU', 'T2_has_#2LL892UU', 'T1_has_#2LLRJGPVV8', 'T2_has_#2LLRJGPVV8', 'T1_has_#2LQ0RGCRU', 'T2_has_#2LQ0RGCRU', 'T1_has_#2LQ8LYRCV', 'T2_has_#2LQ8LYRCV', 'T1_has_#2LUL0RU0L9', 'T2_has_#2LUL0RU0L9', 'T1_has_#2LVQPP2LUJ', 'T2_has_#2LVQPP2LUJ', 'T1_has_#2LVRPCURC', 'T2_has_#2LVRPCURC', 'T1_has_#2LYCUJJJ8', 'T2_has_#2LYCUJJJ8', 'T1_has_#2P0V0CQQ2', 'T2_has_#2P0V0CQQ2', 'T1_has_#2P20J2UU', 'T2_has_#2P20J2UU', 'T1_has_#2P2CCPRUU', 'T2_has_#2P2CCPRUU', 'T1_has_#2P82G2PG8', 'T2_has_#2P82G2PG8', 'T1_has_#2P8RVJVUY', 'T2_has_#2P8RVJVUY', 'T1_has_#2P92JPJPC', 'T2_has_#2P92JPJPC', 'T1_has_#2P9Q0PYRY', 'T2_has_#2P9Q0PYRY', 'T1_has_#2PCJG0G0PG', 'T2_has_#2PCJG0G0PG', 'T1_has_#2PGGR8Y9P', 'T2_has_#2PGGR8Y9P', 'T1_has_#2PLVJ0GLV', 'T2_has_#2PLVJ0GLV', 'T1_has_#2PRVY98GY', 'T2_has_#2PRVY98GY', 'T1_has_#2PV9R9Q28', 'T2_has_#2PV9R9Q28', 'T1_has_#2Q028GQQP', 'T2_has_#2Q028GQQP', 'T1_has_#2Q892QVU', 'T2_has_#2Q892QVU', 'T1_has_#2Q8990UQ', 'T2_has_#2Q8990UQ', 'T1_has_#2QG9LQQC8Y', 'T2_has_#2QG9LQQC8Y', 'T1_has_#2QJJ92L0RJ', 'T2_has_#2QJJ92L0RJ', 'T1_has_#2QVUVPR', 'T2_has_#2QVUVPR', 'T1_has_#2QYJJLPRR', 'T2_has_#2QYJJLPRR', 'T1_has_#2R80JP0JC', 'T2_has_#2R80JP0JC', 'T1_has_#2R8QLCUG0', 'T2_has_#2R8QLCUG0', 'T1_has_#2R8UYJRL', 'T2_has_#2R8UYJRL', 'T1_has_#2R99CCQ9Q', 'T2_has_#2R99CCQ9Q', 'T1_has_#2R9U2C2JP', 'T2_has_#2R9U2C2JP', 'T1_has_#2RR2RU8UL', 'T2_has_#2RR2RU8UL', 'T1_has_#2U2QUP9UV', 'T2_has_#2U2QUP9UV', 'T1_has_#2UL00LYLR', 'T2_has_#2UL00LYLR', 'T1_has_#2UQCRP90', 'T2_has_#2UQCRP90', 'T1_has_#2UVGGL8GR', 'T2_has_#2UVGGL8GR', 'T1_has_#2V08UR9Y2', 'T2_has_#2V08UR9Y2', 'T1_has_#2V09L2UC0', 'T2_has_#2V09L2UC0', 'T1_has_#2VJCCCQGP', 'T2_has_#2VJCCCQGP', 'T1_has_#2VUG0JU8Y', 'T2_has_#2VUG0JU8Y', 'T1_has_#2VVJ08CUY', 'T2_has_#2VVJ08CUY', 'T1_has_#2VY809Q0G', 'T2_has_#2VY809Q0G', 'T1_has_#2VYLC88LY', 'T2_has_#2VYLC88LY', 'T1_has_#2Y20JR8CQ', 'T2_has_#2Y20JR8CQ', 'T1_has_#2Y9CQGCRR', 'T2_has_#2Y9CQGCRR', 'T1_has_#2YGLPCLJ2', 'T2_has_#2YGLPCLJ2', 'T1_has_#2YGU9VVRV', 'T2_has_#2YGU9VVRV', 'T1_has_#2YJCCY2J', 'T2_has_#2YJCCY2J', 'T1_has_#2YL90PYUL', 'T2_has_#2YL90PYUL', 'T1_has_#2YU902JRQ', 'T2_has_#2YU902JRQ', 'T1_has_#2YYJYPCL', 'T2_has_#2YYJYPCL', 'T1_has_#802LCV99Q', 'T2_has_#802LCV99Q', 'T1_has_#80PVPCC29', 'T2_has_#80PVPCC29', 'T1_has_#80VLPJCCC', 'T2_has_#80VLPJCCC', 'T1_has_#80YVJGRY', 'T2_has_#80YVJGRY', 'T1_has_#820JCJJG', 'T2_has_#820JCJJG', 'T1_has_#820UUQ2GQ', 'T2_has_#820UUQ2GQ', 'T1_has_#82282VV9Q', 'T2_has_#82282VV9Q', 'T1_has_#822UQPYU2', 'T2_has_#822UQPYU2', 'T1_has_#828UC8VRC', 'T2_has_#828UC8VRC', 'T1_has_#82CGGYGCG', 'T2_has_#82CGGYGCG', 'T1_has_#82GG2RLQG', 'T2_has_#82GG2RLQG', 'T1_has_#82JPG02', 'T2_has_#82JPG02', 'T1_has_#82PQUPGU0', 'T2_has_#82PQUPGU0', 'T1_has_#82QLJ8UY2', 'T2_has_#82QLJ8UY2', 'T1_has_#82RCQCVG', 'T2_has_#82RCQCVG', 'T1_has_#82RGU8PR', 'T2_has_#82RGU8PR', 'T1_has_#82YCVYRQ0', 'T2_has_#82YCVYRQ0', 'T1_has_#8809RJ0CV', 'T2_has_#8809RJ0CV', 'T1_has_#88LLQGP0Q', 'T2_has_#88LLQGP0Q', 'T1_has_#88U9LPCV8', 'T2_has_#88U9LPCV8', 'T1_has_#88UVVLYUC', 'T2_has_#88UVVLYUC', 'T1_has_#88V8UUGRG', 'T2_has_#88V8UUGRG', 'T1_has_#88Y8UGPG', 'T2_has_#88Y8UGPG', 'T1_has_#890J9RRP2', 'T2_has_#890J9RRP2', 'T1_has_#892YQG9GQ', 'T2_has_#892YQG9GQ', 'T1_has_#8982L9QYP', 'T2_has_#8982L9QYP', 'T1_has_#89GUU92L2', 'T2_has_#89GUU92L2', 'T1_has_#89PVJG9R0', 'T2_has_#89PVJG9R0', 'T1_has_#89RPVY92Q', 'T2_has_#89RPVY92Q', 'T1_has_#89UUQLJCC', 'T2_has_#89UUQLJCC', 'T1_has_#8C8VQUL08', 'T2_has_#8C8VQUL08', 'T1_has_#8CG0RLUG9', 'T2_has_#8CG0RLUG9', 'T1_has_#8CQ2VL8L', 'T2_has_#8CQ2VL8L', 'T1_has_#8CR2R99Q2', 'T2_has_#8CR2R99Q2', 'T1_has_#8CY0V9RGL', 'T2_has_#8CY0V9RGL', 'T1_has_#8CY2Q2G92', 'T2_has_#8CY2Q2G92', 'T1_has_#8G2P8LQJY', 'T2_has_#8G2P8LQJY', 'T1_has_#8G2QUQVP', 'T2_has_#8G2QUQVP', 'T1_has_#8GUPLYY', 'T2_has_#8GUPLYY', 'T1_has_#8GUUPCGL', 'T2_has_#8GUUPCGL', 'T1_has_#8J29RU8G2', 'T2_has_#8J29RU8G2', 'T1_has_#8J8U8L9YG', 'T2_has_#8J8U8L9YG', 'T1_has_#8J9PGVLQG', 'T2_has_#8J9PGVLQG', 'T1_has_#8JQ8PYJ0R', 'T2_has_#8JQ8PYJ0R', 'T1_has_#8JR0209R0', 'T2_has_#8JR0209R0', 'T1_has_#8JRLCJCYJ', 'T2_has_#8JRLCJCYJ', 'T1_has_#8LQR0UU2', 'T2_has_#8LQR0UU2', 'T1_has_#8R2V0P0', 'T2_has_#8R2V0P0', 'T1_has_#8RC22JGRV', 'T2_has_#8RC22JGRV', 'T1_has_#8RJY8P9C', 'T2_has_#8RJY8P9C', 'T1_has_#8RUGQUQ2C', 'T2_has_#8RUGQUQ2C', 'T1_has_#8U0UJQUV', 'T2_has_#8U0UJQUV', 'T1_has_#8U2C0VQR8', 'T2_has_#8U2C0VQR8', 'T1_has_#8U2C2UYCP', 'T2_has_#8U2C2UYCP', 'T1_has_#8UGJ82UL2', 'T2_has_#8UGJ82UL2', 'T1_has_#8UJRGJYJ', 'T2_has_#8UJRGJYJ', 'T1_has_#8ULC0GP8J', 'T2_has_#8ULC0GP8J', 'T1_has_#8ULYPRQ8U', 'T2_has_#8ULYPRQ8U', 'T1_has_#8UQYJ8UU2', 'T2_has_#8UQYJ8UU2', 'T1_has_#8V20RP8Y9', 'T2_has_#8V20RP8Y9', 'T1_has_#8V92UYCJ', 'T2_has_#8V92UYCJ', 'T1_has_#8VJPLPYGL', 'T2_has_#8VJPLPYGL', 'T1_has_#8VUVPCY8J', 'T2_has_#8VUVPCY8J', 'T1_has_#8Y02JLQL9', 'T2_has_#8Y02JLQL9', 'T1_has_#8Y02VRGR', 'T2_has_#8Y02VRGR', 'T1_has_#8Y20VC9L9', 'T2_has_#8Y20VC9L9', 'T1_has_#8Y2Y0GYYG', 'T2_has_#8Y2Y0GYYG', 'T1_has_#8Y98Q8U', 'T2_has_#8Y98Q8U', 'T1_has_#8Y9CPCCJ8', 'T2_has_#8Y9CPCCJ8', 'T1_has_#900RPURLV', 'T2_has_#900RPURLV', 'T1_has_#90CUVVL2R', 'T2_has_#90CUVVL2R', 'T1_has_#90J0R9LPP', 'T2_has_#90J0R9LPP', 'T1_has_#90JCYPQU', 'T2_has_#90JCYPQU', 'T1_has_#90UJQY2RC', 'T2_has_#90UJQY2RC', 'T1_has_#920C8JVUP', 'T2_has_#920C8JVUP', 'T1_has_#92CU2LLY9', 'T2_has_#92CU2LLY9', 'T1_has_#92VJ9V29V', 'T2_has_#92VJ9V29V', 'T1_has_#98C22JLRV', 'T2_has_#98C22JLRV', 'T1_has_#98QJJGP8P', 'T2_has_#98QJJGP8P', 'T1_has_#999YGVQ', 'T2_has_#999YGVQ', 'T1_has_#99GGUPY2U', 'T2_has_#99GGUPY2U', 'T1_has_#99YL9LULY', 'T2_has_#99YL9LULY', 'T1_has_#9C88GC8L8', 'T2_has_#9C88GC8L8', 'T1_has_#9CPYUCGQC', 'T2_has_#9CPYUCGQC', 'T1_has_#9CUQ9CVQQ', 'T2_has_#9CUQ9CVQQ', 'T1_has_#9CVGV0RJ2', 'T2_has_#9CVGV0RJ2', 'T1_has_#9CYYLLRYL', 'T2_has_#9CYYLLRYL', 'T1_has_#9G0Y9LG', 'T2_has_#9G0Y9LG', 'T1_has_#9G209L0LQ', 'T2_has_#9G209L0LQ', 'T1_has_#9GPVJ8Q9U', 'T2_has_#9GPVJ8Q9U', 'T1_has_#9GQQPJ0UG', 'T2_has_#9GQQPJ0UG', 'T1_has_#9GRCCV2G', 'T2_has_#9GRCCV2G', 'T1_has_#9JCG0VY8U', 'T2_has_#9JCG0VY8U', 'T1_has_#9JYG98GG', 'T2_has_#9JYG98GG', 'T1_has_#9L0J88QJ', 'T2_has_#9L0J88QJ', 'T1_has_#9L0UJ90VP', 'T2_has_#9L0UJ90VP', 'T1_has_#9L2Y2Y0VP', 'T2_has_#9L2Y2Y0VP', 'T1_has_#9LCC8LYLV', 'T2_has_#9LCC8LYLV', 'T1_has_#9LRCVUPCU', 'T2_has_#9LRCVUPCU', 'T1_has_#9LVUC2PY', 'T2_has_#9LVUC2PY', 'T1_has_#9P2YGGCV0', 'T2_has_#9P2YGGCV0', 'T1_has_#9PCV9L982', 'T2_has_#9PCV9L982', 'T1_has_#9PJQ9V8L9', 'T2_has_#9PJQ9V8L9', 'T1_has_#9PLCQYUV', 'T2_has_#9PLCQYUV', 'T1_has_#9PQQ8GQQ', 'T2_has_#9PQQ8GQQ', 'T1_has_#9Q22C88V8', 'T2_has_#9Q22C88V8', 'T1_has_#9QCJPL20', 'T2_has_#9QCJPL20', 'T1_has_#9QUY0PYGP', 'T2_has_#9QUY0PYGP', 'T1_has_#9RVPL0Q0P', 'T2_has_#9RVPL0Q0P', 'T1_has_#9UGLGV28R', 'T2_has_#9UGLGV28R', 'T1_has_#9ULYPV8', 'T2_has_#9ULYPV8', 'T1_has_#9UU0RQ9Q', 'T2_has_#9UU0RQ9Q', 'T1_has_#9UUGVYJ', 'T2_has_#9UUGVYJ', 'T1_has_#9V8GJRUV8', 'T2_has_#9V8GJRUV8', 'T1_has_#9VCULVCP', 'T2_has_#9VCULVCP', 'T1_has_#9VJYJ99JR', 'T2_has_#9VJYJ99JR', 'T1_has_#9VL229Y8Y', 'T2_has_#9VL229Y8Y', 'T1_has_#9Y9GLL2QY', 'T2_has_#9Y9GLL2QY', 'T1_has_#9YQ28J0V', 'T2_has_#9YQ28J0V', 'T1_has_#9YQ9VPYUU', 'T2_has_#9YQ9VPYUU', 'T1_has_#9YV2JY2QU', 'T2_has_#9YV2JY2QU', 'T1_has_#9YYY9JVJP', 'T2_has_#9YYY9JVJP', 'T1_has_#C2UL89UL', 'T2_has_#C2UL89UL', 'T1_has_#C8PLV8Y0', 'T2_has_#C8PLV8Y0', 'T1_has_#C8RVRJPU', 'T2_has_#C8RVRJPU', 'T1_has_#C9YCR2GC', 'T2_has_#C9YCR2GC', 'T1_has_#CCGG0JUP', 'T2_has_#CCGG0JUP', 'T1_has_#CJV2PJ0R', 'T2_has_#CJV2PJ0R', 'T1_has_#CPQJ2JLV', 'T2_has_#CPQJ2JLV', 'T1_has_#CQ00V99', 'T2_has_#CQ00V99', 'T1_has_#CUGVUYPG', 'T2_has_#CUGVUYPG', 'T1_has_#CUJQRCQJ', 'T2_has_#CUJQRCQJ', 'T1_has_#CVQ82LUC', 'T2_has_#CVQ82LUC', 'T1_has_#G2Q0R8CV', 'T2_has_#G2Q0R8CV', 'T1_has_#G2QPLPL', 'T2_has_#G2QPLPL', 'T1_has_#GCJCRVQ8', 'T2_has_#GCJCRVQ8', 'T1_has_#GGPPQLUU', 'T2_has_#GGPPQLUU', 'T1_has_#GGUQCG0G', 'T2_has_#GGUQCG0G', 'T1_has_#GGY0G29PU', 'T2_has_#GGY0G29PU', 'T1_has_#GJPVYUQG', 'T2_has_#GJPVYUQG', 'T1_has_#GJRVQVVV0', 'T2_has_#GJRVQVVV0', 'T1_has_#GLQLUPGL0', 'T2_has_#GLQLUPGL0', 'T1_has_#GPLVLQY2', 'T2_has_#GPLVLQY2', 'T1_has_#GPPRCRLQG', 'T2_has_#GPPRCRLQG', 'T1_has_#GQLQQYUVL', 'T2_has_#GQLQQYUVL', 'T1_has_#GRRGLVVJV', 'T2_has_#GRRGLVVJV', 'T1_has_#GRUQ0J8U', 'T2_has_#GRUQ0J8U', 'T1_has_#GRYV92CC', 'T2_has_#GRYV92CC', 'T1_has_#GU8G9JVPY', 'T2_has_#GU8G9JVPY', 'T1_has_#GVCU0U9L', 'T2_has_#GVCU0U9L', 'T1_has_#GVLRUG9Q', 'T2_has_#GVLRUG9Q', 'T1_has_#GVYLVUGR', 'T2_has_#GVYLVUGR', 'T1_has_#GY2UUC99', 'T2_has_#GY2UUC99', 'T1_has_#GYCYCLRJL', 'T2_has_#GYCYCLRJL', 'T1_has_#J089RQ', 'T2_has_#J089RQ', 'T1_has_#J0UVQUR0', 'T2_has_#J0UVQUR0', 'T1_has_#J2L2C0RJ', 'T2_has_#J2L2C0RJ', 'T1_has_#J99YU9QY', 'T2_has_#J99YU9QY', 'T1_has_#J9UQLY9P', 'T2_has_#J9UQLY9P', 'T1_has_#J9V89VU0', 'T2_has_#J9V89VU0', 'T1_has_#JCGLQ', 'T2_has_#JCGLQ', 'T1_has_#JG9VPQL0', 'T2_has_#JG9VPQL0', 'T1_has_#JJ09PC0P', 'T2_has_#JJ09PC0P', 'T1_has_#JL0Q2Q0P', 'T2_has_#JL0Q2Q0P', 'T1_has_#JQ8L0YYL', 'T2_has_#JQ8L0YYL', 'T1_has_#JQ8LLLY', 'T2_has_#JQ8LLLY', 'T1_has_#JQ92PL90', 'T2_has_#JQ92PL90', 'T1_has_#JU9YUUYC', 'T2_has_#JU9YUUYC', 'T1_has_#JUPUR90G', 'T2_has_#JUPUR90G', 'T1_has_#JUPVCGVL', 'T2_has_#JUPVCGVL', 'T1_has_#JVRCVJ9Q', 'T2_has_#JVRCVJ9Q', 'T1_has_#JVVLV0UR', 'T2_has_#JVVLV0UR', 'T1_has_#L08Q9J09', 'T2_has_#L08Q9J09', 'T1_has_#L0UYUYJV9', 'T2_has_#L0UYUYJV9', 'T1_has_#L8YGJQ02J', 'T2_has_#L8YGJQ02J', 'T1_has_#L8YQV2V9R', 'T2_has_#L8YQV2V9R', 'T1_has_#L9PQUV0YC', 'T2_has_#L9PQUV0YC', 'T1_has_#L9PRPQVQJ', 'T2_has_#L9PRPQVQJ', 'T1_has_#LG8PCJG8', 'T2_has_#LG8PCJG8', 'T1_has_#LGVY0QGP9', 'T2_has_#LGVY0QGP9', 'T1_has_#LGYC9Q9CG', 'T2_has_#LGYC9Q9CG', 'T1_has_#LJ0288PRG', 'T2_has_#LJ0288PRG', 'T1_has_#LJUC0VGR', 'T2_has_#LJUC0VGR', 'T1_has_#LLV9L9QPQ', 'T2_has_#LLV9L9QPQ', 'T1_has_#LP22LRYPR', 'T2_has_#LP22LRYPR', 'T1_has_#LP2LVRRU', 'T2_has_#LP2LVRRU', 'T1_has_#LR08G9C8', 'T2_has_#LR08G9C8', 'T1_has_#LRQVGYRGC', 'T2_has_#LRQVGYRGC', 'T1_has_#LU8V9Y9', 'T2_has_#LU8V9Y9', 'T1_has_#LV2YCGJ9', 'T2_has_#LV2YCGJ9', 'T1_has_#LVRRYPV', 'T2_has_#LVRRYPV', 'T1_has_#LYGVU8C', 'T2_has_#LYGVU8C', 'T1_has_#LYR0Q9C', 'T2_has_#LYR0Q9C', 'T1_has_#P02J299GU', 'T2_has_#P02J299GU', 'T1_has_#P0LYVV8J', 'T2_has_#P0LYVV8J', 'T1_has_#P0Y8JGL0U', 'T2_has_#P0Y8JGL0U', 'T1_has_#P0YCRUCJY', 'T2_has_#P0YCRUCJY', 'T1_has_#P20V908QU', 'T2_has_#P20V908QU', 'T1_has_#P22GLVULL', 'T2_has_#P22GLVULL', 'T1_has_#P22U8228G', 'T2_has_#P22U8228G', 'T1_has_#P2808PRC', 'T2_has_#P2808PRC', 'T1_has_#P2P0VR0G', 'T2_has_#P2P0VR0G', 'T1_has_#P2PRC2YQQ', 'T2_has_#P2PRC2YQQ', 'T1_has_#P8Y2RQ2RL', 'T2_has_#P8Y2RQ2RL', 'T1_has_#P90GVUV80', 'T2_has_#P90GVUV80', 'T1_has_#P90RJQ8C', 'T2_has_#P90RJQ8C', 'T1_has_#P92R9L28G', 'T2_has_#P92R9L28G', 'T1_has_#P9G88YY9J', 'T2_has_#P9G88YY9J', 'T1_has_#P9QYU0QYR', 'T2_has_#P9QYU0QYR', 'T1_has_#PCJL8Q82U', 'T2_has_#PCJL8Q82U', 'T1_has_#PCPRPJV', 'T2_has_#PCPRPJV', 'T1_has_#PCUL0C98P', 'T2_has_#PCUL0C98P', 'T1_has_#PG0JYVQPQ', 'T2_has_#PG0JYVQPQ', 'T1_has_#PG8YCGGCV', 'T2_has_#PG8YCGGCV', 'T1_has_#PGGJQP2PQ', 'T2_has_#PGGJQP2PQ', 'T1_has_#PGJRY8QJ0', 'T2_has_#PGJRY8QJ0', 'T1_has_#PGL2UL0CR', 'T2_has_#PGL2UL0CR', 'T1_has_#PGYCUCUYG', 'T2_has_#PGYCUCUYG', 'T1_has_#PJGGV2Q80', 'T2_has_#PJGGV2Q80', 'T1_has_#PJQG89R2J', 'T2_has_#PJQG89R2J', 'T1_has_#PLLRJC2V', 'T2_has_#PLLRJC2V', 'T1_has_#PLQ9U80G2', 'T2_has_#PLQ9U80G2', 'T1_has_#PLV89CGP', 'T2_has_#PLV89CGP', 'T1_has_#PLVYRR929', 'T2_has_#PLVYRR929', 'T1_has_#PPG8C2P2', 'T2_has_#PPG8C2P2', 'T1_has_#PPPPJL88R', 'T2_has_#PPPPJL88R', 'T1_has_#PPQ8VV2', 'T2_has_#PPQ8VV2', 'T1_has_#PQ9C9RQ', 'T2_has_#PQ9C9RQ', 'T1_has_#PR0P8QVQ', 'T2_has_#PR0P8QVQ', 'T1_has_#PR9U2JL', 'T2_has_#PR9U2JL', 'T1_has_#PU20LUCQG', 'T2_has_#PU20LUCQG', 'T1_has_#PU8RPR29G', 'T2_has_#PU8RPR29G', 'T1_has_#PU8VPU2GV', 'T2_has_#PU8VPU2GV', 'T1_has_#PUPCGJQQR', 'T2_has_#PUPCGJQQR', 'T1_has_#PURJRYR29', 'T2_has_#PURJRYR29', 'T1_has_#PUYRPJ2VC', 'T2_has_#PUYRPJ2VC', 'T1_has_#PVQ9QUY', 'T2_has_#PVQ9QUY', 'T1_has_#PVRLUJU', 'T2_has_#PVRLUJU', 'T1_has_#PY2RR0UCQ', 'T2_has_#PY2RR0UCQ', 'T1_has_#Q22ULY9JY', 'T2_has_#Q22ULY9JY', 'T1_has_#Q2VCLG9Y9', 'T2_has_#Q2VCLG9Y9', 'T1_has_#Q2VQVC9', 'T2_has_#Q2VQVC9', 'T1_has_#Q2Y2220UG', 'T2_has_#Q2Y2220UG', 'T1_has_#Q808R2CV', 'T2_has_#Q808R2CV', 'T1_has_#Q9LPQYRU9', 'T2_has_#Q9LPQYRU9', 'T1_has_#QCC9RVYQQ', 'T2_has_#QCC9RVYQQ', 'T1_has_#QJQ0YPV', 'T2_has_#QJQ0YPV', 'T1_has_#QJULVGU', 'T2_has_#QJULVGU', 'T1_has_#QL8J82G8', 'T2_has_#QL8J82G8', 'T1_has_#QLCJGQUP', 'T2_has_#QLCJGQUP', 'T1_has_#QLQQUUU0', 'T2_has_#QLQQUUU0', 'T1_has_#QLVU09CY', 'T2_has_#QLVU09CY', 'T1_has_#QPVJYY8JQ', 'T2_has_#QPVJYY8JQ', 'T1_has_#QQJLG9P2Q', 'T2_has_#QQJLG9P2Q', 'T1_has_#QUG9RP9', 'T2_has_#QUG9RP9', 'T1_has_#QURVLPG', 'T2_has_#QURVLPG', 'T1_has_#QUYCVC2', 'T2_has_#QUYCVC2', 'T1_has_#QVULGUV', 'T2_has_#QVULGUV', 'T1_has_#R0PPJ9PV', 'T2_has_#R0PPJ9PV', 'T1_has_#R0VQ82GU', 'T2_has_#R0VQ82GU', 'T1_has_#R2LR2QLG', 'T2_has_#R2LR2QLG', 'T1_has_#R8Q0C2P2', 'T2_has_#R8Q0C2P2', 'T1_has_#R9C0J2P2', 'T2_has_#R9C0J2P2', 'T1_has_#R9CCLP8Q', 'T2_has_#R9CCLP8Q', 'T1_has_#RCYQUJU0', 'T2_has_#RCYQUJU0', 'T1_has_#RGUGP9R', 'T2_has_#RGUGP9R', 'T1_has_#RL02R0GR', 'T2_has_#RL02R0GR', 'T1_has_#RPUYRP8V', 'T2_has_#RPUYRP8V', 'T1_has_#RV9JGVYL', 'T2_has_#RV9JGVYL', 'T1_has_#RVL0RPR9', 'T2_has_#RVL0RPR9', 'T1_has_#U0JVLJGG', 'T2_has_#U0JVLJGG', 'T1_has_#U9GC8G02', 'T2_has_#U9GC8G02', 'T1_has_#UJ2Y90PV', 'T2_has_#UJ2Y90PV', 'T1_has_#UR2UCYQR', 'T2_has_#UR2UCYQR', 'T1_has_#UR2UL8YR', 'T2_has_#UR2UL8YR', 'T1_has_#URV8JPY', 'T2_has_#URV8JPY', 'T1_has_#UUU0V8CG', 'T2_has_#UUU0V8CG', 'T1_has_#V0QQCV80', 'T2_has_#V0QQCV80', 'T1_has_#V89Y2GP0', 'T2_has_#V89Y2GP0', 'T1_has_#V8P2CCY', 'T2_has_#V8P2CCY', 'T1_has_#VGVG2R0V', 'T2_has_#VGVG2R0V', 'T1_has_#VJ2QCPV9', 'T2_has_#VJ2QCPV9', 'T1_has_#VJUQ0Y', 'T2_has_#VJUQ0Y', 'T1_has_#VPVLG2', 'T2_has_#VPVLG2', 'T1_has_#VYGUP9Q0', 'T2_has_#VYGUP9Q0', 'T1_has_#Y0VGCP2QU', 'T2_has_#Y0VGCP2QU', 'T1_has_#Y2VUV8UYV', 'T2_has_#Y2VUV8UYV', 'T1_has_#Y8PLP8VY', 'T2_has_#Y8PLP8VY', 'T1_has_#Y8PLRJR', 'T2_has_#Y8PLRJR', 'T1_has_#Y9C2GYL9Q', 'T2_has_#Y9C2GYL9Q', 'T1_has_#Y9GCL099J', 'T2_has_#Y9GCL099J', 'T1_has_#Y9R8GCCQ', 'T2_has_#Y9R8GCCQ', 'T1_has_#Y9YCGLJ9C', 'T2_has_#Y9YCGLJ9C', 'T1_has_#YCUGURU89', 'T2_has_#YCUGURU89', 'T1_has_#YG0LVYRRY', 'T2_has_#YG0LVYRRY', 'T1_has_#YGQ2PQP0R', 'T2_has_#YGQ2PQP0R', 'T1_has_#YGQUQ2QPP', 'T2_has_#YGQUQ2QPP', 'T1_has_#YGQYGCR', 'T2_has_#YGQYGCR', 'T1_has_#YL2LUYYLG', 'T2_has_#YL2LUYYLG', 'T1_has_#YQLP8LP8', 'T2_has_#YQLP8LP8', 'T1_has_#YQUCCJ2', 'T2_has_#YQUCCJ2', 'T1_has_#YQV0JVPV', 'T2_has_#YQV0JVPV', 'T1_has_#YR2Y9JRCC', 'T2_has_#YR2Y9JRCC', 'T1_has_#YRQ8RP0C9', 'T2_has_#YRQ8RP0C9', 'T1_has_#YUYYLVJ', 'T2_has_#YUYYLVJ', 'T1_has_#YVQ0R9QL', 'T2_has_#YVQ0R9QL', 'T1_has_#YVQCUGV9', 'T2_has_#YVQCUGV9']\n",
      "['Mode', 'Map', 'T1_has_#2028JJP8P', 'T2_has_#2028JJP8P', 'T1_has_#202GJJR28', 'T2_has_#202GJJR28', 'T1_has_#202GYRU0', 'T2_has_#202GYRU0', 'T1_has_#2092LGRLR', 'T2_has_#2092LGRLR', 'T1_has_#20C0LL00', 'T2_has_#20C0LL00', 'T1_has_#20JC8GJLQ', 'T2_has_#20JC8GJLQ', 'T1_has_#20JP809C2', 'T2_has_#20JP809C2', 'T1_has_#20JU9YJJP', 'T2_has_#20JU9YJJP', 'T1_has_#20L0C9GCP', 'T2_has_#20L0C9GCP', 'T1_has_#20L88L2J', 'T2_has_#20L88L2J', 'T1_has_#20PVYLJQG', 'T2_has_#20PVYLJQG', 'T1_has_#2208QGGGL', 'T2_has_#2208QGGGL', 'T1_has_#220PGLU02', 'T2_has_#220PGLU02', 'T1_has_#220UJU8P2', 'T2_has_#220UJU8P2', 'T1_has_#222R82RCU', 'T2_has_#222R82RCU', 'T1_has_#2282LR0YG', 'T2_has_#2282LR0YG', 'T1_has_#2288RRJJG', 'T2_has_#2288RRJJG', 'T1_has_#229CQLP0QV', 'T2_has_#229CQLP0QV', 'T1_has_#22CL00PG0', 'T2_has_#22CL00PG0', 'T1_has_#22JR2JLYC', 'T2_has_#22JR2JLYC', 'T1_has_#280RJ29R9', 'T2_has_#280RJ29R9', 'T1_has_#28CL0QVRQV', 'T2_has_#28CL0QVRQV', 'T1_has_#28LUY98', 'T2_has_#28LUY98', 'T1_has_#28PCVLJCL', 'T2_has_#28PCVLJCL', 'T1_has_#28PPLLJ8U', 'T2_has_#28PPLLJ8U', 'T1_has_#28PU0P9L0', 'T2_has_#28PU0P9L0', 'T1_has_#28Q8CQUCP', 'T2_has_#28Q8CQUCP', 'T1_has_#28RRQCQ9J', 'T2_has_#28RRQCQ9J', 'T1_has_#2909LRLU', 'T2_has_#2909LRLU', 'T1_has_#2920VCVJJ', 'T2_has_#2920VCVJJ', 'T1_has_#29G0CYLU9', 'T2_has_#29G0CYLU9', 'T1_has_#29JJ20UG', 'T2_has_#29JJ20UG', 'T1_has_#29P0GP8UC', 'T2_has_#29P0GP8UC', 'T1_has_#29P9J89CP', 'T2_has_#29P9J89CP', 'T1_has_#29Q2V0LGU', 'T2_has_#29Q2V0LGU', 'T1_has_#29QGPVP2V', 'T2_has_#29QGPVP2V', 'T1_has_#29RJQLQQU', 'T2_has_#29RJQLQQU', 'T1_has_#29U29P80R', 'T2_has_#29U29P80R', 'T1_has_#29UGLJV2G', 'T2_has_#29UGLJV2G', 'T1_has_#29VRJU08C', 'T2_has_#29VRJU08C', 'T1_has_#2C80JVR8C', 'T2_has_#2C80JVR8C', 'T1_has_#2CJ0RCJ', 'T2_has_#2CJ0RCJ', 'T1_has_#2CLR2YQY', 'T2_has_#2CLR2YQY', 'T1_has_#2CQ0U882Q', 'T2_has_#2CQ0U882Q', 'T1_has_#2CY80RQUY', 'T2_has_#2CY80RQUY', 'T1_has_#2G0RRLU2R', 'T2_has_#2G0RRLU2R', 'T1_has_#2G82CGU', 'T2_has_#2G82CGU', 'T1_has_#2GV90L8YP', 'T2_has_#2GV90L8YP', 'T1_has_#2GVY09J2', 'T2_has_#2GVY09J2', 'T1_has_#2GYQ0QL', 'T2_has_#2GYQ0QL', 'T1_has_#2J0G220PC', 'T2_has_#2J0G220PC', 'T1_has_#2J8V8L0V2', 'T2_has_#2J8V8L0V2', 'T1_has_#2JLVRQ9', 'T2_has_#2JLVRQ9', 'T1_has_#2JQU8JQ2G', 'T2_has_#2JQU8JQ2G', 'T1_has_#2L08U08RUQ', 'T2_has_#2L08U08RUQ', 'T1_has_#2L89R02JV', 'T2_has_#2L89R02JV', 'T1_has_#2LCU2QGRJY', 'T2_has_#2LCU2QGRJY', 'T1_has_#2LG8QJ9L', 'T2_has_#2LG8QJ9L', 'T1_has_#2LL892UU', 'T2_has_#2LL892UU', 'T1_has_#2LLRJGPVV8', 'T2_has_#2LLRJGPVV8', 'T1_has_#2LQ0RGCRU', 'T2_has_#2LQ0RGCRU', 'T1_has_#2LQ8LYRCV', 'T2_has_#2LQ8LYRCV', 'T1_has_#2LUL0RU0L9', 'T2_has_#2LUL0RU0L9', 'T1_has_#2LVQPP2LUJ', 'T2_has_#2LVQPP2LUJ', 'T1_has_#2LVRPCURC', 'T2_has_#2LVRPCURC', 'T1_has_#2LYCUJJJ8', 'T2_has_#2LYCUJJJ8', 'T1_has_#2P0V0CQQ2', 'T2_has_#2P0V0CQQ2', 'T1_has_#2P20J2UU', 'T2_has_#2P20J2UU', 'T1_has_#2P2CCPRUU', 'T2_has_#2P2CCPRUU', 'T1_has_#2P82G2PG8', 'T2_has_#2P82G2PG8', 'T1_has_#2P8RVJVUY', 'T2_has_#2P8RVJVUY', 'T1_has_#2P92JPJPC', 'T2_has_#2P92JPJPC', 'T1_has_#2P9Q0PYRY', 'T2_has_#2P9Q0PYRY', 'T1_has_#2PCJG0G0PG', 'T2_has_#2PCJG0G0PG', 'T1_has_#2PGGR8Y9P', 'T2_has_#2PGGR8Y9P', 'T1_has_#2PLVJ0GLV', 'T2_has_#2PLVJ0GLV', 'T1_has_#2PRVY98GY', 'T2_has_#2PRVY98GY', 'T1_has_#2PV9R9Q28', 'T2_has_#2PV9R9Q28', 'T1_has_#2Q028GQQP', 'T2_has_#2Q028GQQP', 'T1_has_#2Q892QVU', 'T2_has_#2Q892QVU', 'T1_has_#2Q8990UQ', 'T2_has_#2Q8990UQ', 'T1_has_#2QG9LQQC8Y', 'T2_has_#2QG9LQQC8Y', 'T1_has_#2QJJ92L0RJ', 'T2_has_#2QJJ92L0RJ', 'T1_has_#2QVUVPR', 'T2_has_#2QVUVPR', 'T1_has_#2QYJJLPRR', 'T2_has_#2QYJJLPRR', 'T1_has_#2R80JP0JC', 'T2_has_#2R80JP0JC', 'T1_has_#2R8QLCUG0', 'T2_has_#2R8QLCUG0', 'T1_has_#2R8UYJRL', 'T2_has_#2R8UYJRL', 'T1_has_#2R99CCQ9Q', 'T2_has_#2R99CCQ9Q', 'T1_has_#2R9U2C2JP', 'T2_has_#2R9U2C2JP', 'T1_has_#2RR2RU8UL', 'T2_has_#2RR2RU8UL', 'T1_has_#2U2QUP9UV', 'T2_has_#2U2QUP9UV', 'T1_has_#2UL00LYLR', 'T2_has_#2UL00LYLR', 'T1_has_#2UQCRP90', 'T2_has_#2UQCRP90', 'T1_has_#2UVGGL8GR', 'T2_has_#2UVGGL8GR', 'T1_has_#2V08UR9Y2', 'T2_has_#2V08UR9Y2', 'T1_has_#2V09L2UC0', 'T2_has_#2V09L2UC0', 'T1_has_#2VJCCCQGP', 'T2_has_#2VJCCCQGP', 'T1_has_#2VUG0JU8Y', 'T2_has_#2VUG0JU8Y', 'T1_has_#2VVJ08CUY', 'T2_has_#2VVJ08CUY', 'T1_has_#2VY809Q0G', 'T2_has_#2VY809Q0G', 'T1_has_#2VYLC88LY', 'T2_has_#2VYLC88LY', 'T1_has_#2Y20JR8CQ', 'T2_has_#2Y20JR8CQ', 'T1_has_#2Y9CQGCRR', 'T2_has_#2Y9CQGCRR', 'T1_has_#2YGLPCLJ2', 'T2_has_#2YGLPCLJ2', 'T1_has_#2YGU9VVRV', 'T2_has_#2YGU9VVRV', 'T1_has_#2YJCCY2J', 'T2_has_#2YJCCY2J', 'T1_has_#2YL90PYUL', 'T2_has_#2YL90PYUL', 'T1_has_#2YU902JRQ', 'T2_has_#2YU902JRQ', 'T1_has_#2YYJYPCL', 'T2_has_#2YYJYPCL', 'T1_has_#802LCV99Q', 'T2_has_#802LCV99Q', 'T1_has_#80PVPCC29', 'T2_has_#80PVPCC29', 'T1_has_#80VLPJCCC', 'T2_has_#80VLPJCCC', 'T1_has_#80YVJGRY', 'T2_has_#80YVJGRY', 'T1_has_#820JCJJG', 'T2_has_#820JCJJG', 'T1_has_#820UUQ2GQ', 'T2_has_#820UUQ2GQ', 'T1_has_#82282VV9Q', 'T2_has_#82282VV9Q', 'T1_has_#822UQPYU2', 'T2_has_#822UQPYU2', 'T1_has_#828UC8VRC', 'T2_has_#828UC8VRC', 'T1_has_#82CGGYGCG', 'T2_has_#82CGGYGCG', 'T1_has_#82GG2RLQG', 'T2_has_#82GG2RLQG', 'T1_has_#82JPG02', 'T2_has_#82JPG02', 'T1_has_#82PQUPGU0', 'T2_has_#82PQUPGU0', 'T1_has_#82QLJ8UY2', 'T2_has_#82QLJ8UY2', 'T1_has_#82RCQCVG', 'T2_has_#82RCQCVG', 'T1_has_#82RGU8PR', 'T2_has_#82RGU8PR', 'T1_has_#82YCVYRQ0', 'T2_has_#82YCVYRQ0', 'T1_has_#8809RJ0CV', 'T2_has_#8809RJ0CV', 'T1_has_#88LLQGP0Q', 'T2_has_#88LLQGP0Q', 'T1_has_#88U9LPCV8', 'T2_has_#88U9LPCV8', 'T1_has_#88UVVLYUC', 'T2_has_#88UVVLYUC', 'T1_has_#88V8UUGRG', 'T2_has_#88V8UUGRG', 'T1_has_#88Y8UGPG', 'T2_has_#88Y8UGPG', 'T1_has_#890J9RRP2', 'T2_has_#890J9RRP2', 'T1_has_#892YQG9GQ', 'T2_has_#892YQG9GQ', 'T1_has_#8982L9QYP', 'T2_has_#8982L9QYP', 'T1_has_#89GUU92L2', 'T2_has_#89GUU92L2', 'T1_has_#89PVJG9R0', 'T2_has_#89PVJG9R0', 'T1_has_#89RPVY92Q', 'T2_has_#89RPVY92Q', 'T1_has_#89UUQLJCC', 'T2_has_#89UUQLJCC', 'T1_has_#8C8VQUL08', 'T2_has_#8C8VQUL08', 'T1_has_#8CG0RLUG9', 'T2_has_#8CG0RLUG9', 'T1_has_#8CQ2VL8L', 'T2_has_#8CQ2VL8L', 'T1_has_#8CR2R99Q2', 'T2_has_#8CR2R99Q2', 'T1_has_#8CY0V9RGL', 'T2_has_#8CY0V9RGL', 'T1_has_#8CY2Q2G92', 'T2_has_#8CY2Q2G92', 'T1_has_#8G2P8LQJY', 'T2_has_#8G2P8LQJY', 'T1_has_#8G2QUQVP', 'T2_has_#8G2QUQVP', 'T1_has_#8GUPLYY', 'T2_has_#8GUPLYY', 'T1_has_#8GUUPCGL', 'T2_has_#8GUUPCGL', 'T1_has_#8J29RU8G2', 'T2_has_#8J29RU8G2', 'T1_has_#8J8U8L9YG', 'T2_has_#8J8U8L9YG', 'T1_has_#8J9PGVLQG', 'T2_has_#8J9PGVLQG', 'T1_has_#8JQ8PYJ0R', 'T2_has_#8JQ8PYJ0R', 'T1_has_#8JR0209R0', 'T2_has_#8JR0209R0', 'T1_has_#8JRLCJCYJ', 'T2_has_#8JRLCJCYJ', 'T1_has_#8LQR0UU2', 'T2_has_#8LQR0UU2', 'T1_has_#8R2V0P0', 'T2_has_#8R2V0P0', 'T1_has_#8RC22JGRV', 'T2_has_#8RC22JGRV', 'T1_has_#8RJY8P9C', 'T2_has_#8RJY8P9C', 'T1_has_#8RUGQUQ2C', 'T2_has_#8RUGQUQ2C', 'T1_has_#8U0UJQUV', 'T2_has_#8U0UJQUV', 'T1_has_#8U2C0VQR8', 'T2_has_#8U2C0VQR8', 'T1_has_#8U2C2UYCP', 'T2_has_#8U2C2UYCP', 'T1_has_#8UGJ82UL2', 'T2_has_#8UGJ82UL2', 'T1_has_#8UJRGJYJ', 'T2_has_#8UJRGJYJ', 'T1_has_#8ULC0GP8J', 'T2_has_#8ULC0GP8J', 'T1_has_#8ULYPRQ8U', 'T2_has_#8ULYPRQ8U', 'T1_has_#8UQYJ8UU2', 'T2_has_#8UQYJ8UU2', 'T1_has_#8V20RP8Y9', 'T2_has_#8V20RP8Y9', 'T1_has_#8V92UYCJ', 'T2_has_#8V92UYCJ', 'T1_has_#8VJPLPYGL', 'T2_has_#8VJPLPYGL', 'T1_has_#8VUVPCY8J', 'T2_has_#8VUVPCY8J', 'T1_has_#8Y02JLQL9', 'T2_has_#8Y02JLQL9', 'T1_has_#8Y02VRGR', 'T2_has_#8Y02VRGR', 'T1_has_#8Y20VC9L9', 'T2_has_#8Y20VC9L9', 'T1_has_#8Y2Y0GYYG', 'T2_has_#8Y2Y0GYYG', 'T1_has_#8Y98Q8U', 'T2_has_#8Y98Q8U', 'T1_has_#8Y9CPCCJ8', 'T2_has_#8Y9CPCCJ8', 'T1_has_#900RPURLV', 'T2_has_#900RPURLV', 'T1_has_#90CUVVL2R', 'T2_has_#90CUVVL2R', 'T1_has_#90J0R9LPP', 'T2_has_#90J0R9LPP', 'T1_has_#90JCYPQU', 'T2_has_#90JCYPQU', 'T1_has_#90UJQY2RC', 'T2_has_#90UJQY2RC', 'T1_has_#920C8JVUP', 'T2_has_#920C8JVUP', 'T1_has_#92CU2LLY9', 'T2_has_#92CU2LLY9', 'T1_has_#92VJ9V29V', 'T2_has_#92VJ9V29V', 'T1_has_#98C22JLRV', 'T2_has_#98C22JLRV', 'T1_has_#98QJJGP8P', 'T2_has_#98QJJGP8P', 'T1_has_#999YGVQ', 'T2_has_#999YGVQ', 'T1_has_#99GGUPY2U', 'T2_has_#99GGUPY2U', 'T1_has_#99YL9LULY', 'T2_has_#99YL9LULY', 'T1_has_#9C88GC8L8', 'T2_has_#9C88GC8L8', 'T1_has_#9CPYUCGQC', 'T2_has_#9CPYUCGQC', 'T1_has_#9CUQ9CVQQ', 'T2_has_#9CUQ9CVQQ', 'T1_has_#9CVGV0RJ2', 'T2_has_#9CVGV0RJ2', 'T1_has_#9CYYLLRYL', 'T2_has_#9CYYLLRYL', 'T1_has_#9G0Y9LG', 'T2_has_#9G0Y9LG', 'T1_has_#9G209L0LQ', 'T2_has_#9G209L0LQ', 'T1_has_#9GPVJ8Q9U', 'T2_has_#9GPVJ8Q9U', 'T1_has_#9GQQPJ0UG', 'T2_has_#9GQQPJ0UG', 'T1_has_#9GRCCV2G', 'T2_has_#9GRCCV2G', 'T1_has_#9JCG0VY8U', 'T2_has_#9JCG0VY8U', 'T1_has_#9JYG98GG', 'T2_has_#9JYG98GG', 'T1_has_#9L0J88QJ', 'T2_has_#9L0J88QJ', 'T1_has_#9L0UJ90VP', 'T2_has_#9L0UJ90VP', 'T1_has_#9L2Y2Y0VP', 'T2_has_#9L2Y2Y0VP', 'T1_has_#9LCC8LYLV', 'T2_has_#9LCC8LYLV', 'T1_has_#9LRCVUPCU', 'T2_has_#9LRCVUPCU', 'T1_has_#9LVUC2PY', 'T2_has_#9LVUC2PY', 'T1_has_#9P2YGGCV0', 'T2_has_#9P2YGGCV0', 'T1_has_#9PCV9L982', 'T2_has_#9PCV9L982', 'T1_has_#9PJQ9V8L9', 'T2_has_#9PJQ9V8L9', 'T1_has_#9PLCQYUV', 'T2_has_#9PLCQYUV', 'T1_has_#9PQQ8GQQ', 'T2_has_#9PQQ8GQQ', 'T1_has_#9Q22C88V8', 'T2_has_#9Q22C88V8', 'T1_has_#9QCJPL20', 'T2_has_#9QCJPL20', 'T1_has_#9QUY0PYGP', 'T2_has_#9QUY0PYGP', 'T1_has_#9RVPL0Q0P', 'T2_has_#9RVPL0Q0P', 'T1_has_#9UGLGV28R', 'T2_has_#9UGLGV28R', 'T1_has_#9ULYPV8', 'T2_has_#9ULYPV8', 'T1_has_#9UU0RQ9Q', 'T2_has_#9UU0RQ9Q', 'T1_has_#9UUGVYJ', 'T2_has_#9UUGVYJ', 'T1_has_#9V8GJRUV8', 'T2_has_#9V8GJRUV8', 'T1_has_#9VCULVCP', 'T2_has_#9VCULVCP', 'T1_has_#9VJYJ99JR', 'T2_has_#9VJYJ99JR', 'T1_has_#9VL229Y8Y', 'T2_has_#9VL229Y8Y', 'T1_has_#9Y9GLL2QY', 'T2_has_#9Y9GLL2QY', 'T1_has_#9YQ28J0V', 'T2_has_#9YQ28J0V', 'T1_has_#9YQ9VPYUU', 'T2_has_#9YQ9VPYUU', 'T1_has_#9YV2JY2QU', 'T2_has_#9YV2JY2QU', 'T1_has_#9YYY9JVJP', 'T2_has_#9YYY9JVJP', 'T1_has_#C2UL89UL', 'T2_has_#C2UL89UL', 'T1_has_#C8PLV8Y0', 'T2_has_#C8PLV8Y0', 'T1_has_#C8RVRJPU', 'T2_has_#C8RVRJPU', 'T1_has_#C9YCR2GC', 'T2_has_#C9YCR2GC', 'T1_has_#CCGG0JUP', 'T2_has_#CCGG0JUP', 'T1_has_#CJV2PJ0R', 'T2_has_#CJV2PJ0R', 'T1_has_#CPQJ2JLV', 'T2_has_#CPQJ2JLV', 'T1_has_#CQ00V99', 'T2_has_#CQ00V99', 'T1_has_#CUGVUYPG', 'T2_has_#CUGVUYPG', 'T1_has_#CUJQRCQJ', 'T2_has_#CUJQRCQJ', 'T1_has_#CVQ82LUC', 'T2_has_#CVQ82LUC', 'T1_has_#G2Q0R8CV', 'T2_has_#G2Q0R8CV', 'T1_has_#G2QPLPL', 'T2_has_#G2QPLPL', 'T1_has_#GCJCRVQ8', 'T2_has_#GCJCRVQ8', 'T1_has_#GGPPQLUU', 'T2_has_#GGPPQLUU', 'T1_has_#GGUQCG0G', 'T2_has_#GGUQCG0G', 'T1_has_#GGY0G29PU', 'T2_has_#GGY0G29PU', 'T1_has_#GJPVYUQG', 'T2_has_#GJPVYUQG', 'T1_has_#GJRVQVVV0', 'T2_has_#GJRVQVVV0', 'T1_has_#GLQLUPGL0', 'T2_has_#GLQLUPGL0', 'T1_has_#GPLVLQY2', 'T2_has_#GPLVLQY2', 'T1_has_#GPPRCRLQG', 'T2_has_#GPPRCRLQG', 'T1_has_#GQLQQYUVL', 'T2_has_#GQLQQYUVL', 'T1_has_#GRRGLVVJV', 'T2_has_#GRRGLVVJV', 'T1_has_#GRUQ0J8U', 'T2_has_#GRUQ0J8U', 'T1_has_#GRYV92CC', 'T2_has_#GRYV92CC', 'T1_has_#GU8G9JVPY', 'T2_has_#GU8G9JVPY', 'T1_has_#GVCU0U9L', 'T2_has_#GVCU0U9L', 'T1_has_#GVLRUG9Q', 'T2_has_#GVLRUG9Q', 'T1_has_#GVYLVUGR', 'T2_has_#GVYLVUGR', 'T1_has_#GY2UUC99', 'T2_has_#GY2UUC99', 'T1_has_#GYCYCLRJL', 'T2_has_#GYCYCLRJL', 'T1_has_#J089RQ', 'T2_has_#J089RQ', 'T1_has_#J0UVQUR0', 'T2_has_#J0UVQUR0', 'T1_has_#J2L2C0RJ', 'T2_has_#J2L2C0RJ', 'T1_has_#J99YU9QY', 'T2_has_#J99YU9QY', 'T1_has_#J9UQLY9P', 'T2_has_#J9UQLY9P', 'T1_has_#J9V89VU0', 'T2_has_#J9V89VU0', 'T1_has_#JCGLQ', 'T2_has_#JCGLQ', 'T1_has_#JG9VPQL0', 'T2_has_#JG9VPQL0', 'T1_has_#JJ09PC0P', 'T2_has_#JJ09PC0P', 'T1_has_#JL0Q2Q0P', 'T2_has_#JL0Q2Q0P', 'T1_has_#JQ8L0YYL', 'T2_has_#JQ8L0YYL', 'T1_has_#JQ8LLLY', 'T2_has_#JQ8LLLY', 'T1_has_#JQ92PL90', 'T2_has_#JQ92PL90', 'T1_has_#JU9YUUYC', 'T2_has_#JU9YUUYC', 'T1_has_#JUPUR90G', 'T2_has_#JUPUR90G', 'T1_has_#JUPVCGVL', 'T2_has_#JUPVCGVL', 'T1_has_#JVRCVJ9Q', 'T2_has_#JVRCVJ9Q', 'T1_has_#JVVLV0UR', 'T2_has_#JVVLV0UR', 'T1_has_#L08Q9J09', 'T2_has_#L08Q9J09', 'T1_has_#L0UYUYJV9', 'T2_has_#L0UYUYJV9', 'T1_has_#L8YGJQ02J', 'T2_has_#L8YGJQ02J', 'T1_has_#L8YQV2V9R', 'T2_has_#L8YQV2V9R', 'T1_has_#L9PQUV0YC', 'T2_has_#L9PQUV0YC', 'T1_has_#L9PRPQVQJ', 'T2_has_#L9PRPQVQJ', 'T1_has_#LG8PCJG8', 'T2_has_#LG8PCJG8', 'T1_has_#LGVY0QGP9', 'T2_has_#LGVY0QGP9', 'T1_has_#LGYC9Q9CG', 'T2_has_#LGYC9Q9CG', 'T1_has_#LJ0288PRG', 'T2_has_#LJ0288PRG', 'T1_has_#LJUC0VGR', 'T2_has_#LJUC0VGR', 'T1_has_#LLV9L9QPQ', 'T2_has_#LLV9L9QPQ', 'T1_has_#LP22LRYPR', 'T2_has_#LP22LRYPR', 'T1_has_#LP2LVRRU', 'T2_has_#LP2LVRRU', 'T1_has_#LR08G9C8', 'T2_has_#LR08G9C8', 'T1_has_#LRQVGYRGC', 'T2_has_#LRQVGYRGC', 'T1_has_#LU8V9Y9', 'T2_has_#LU8V9Y9', 'T1_has_#LV2YCGJ9', 'T2_has_#LV2YCGJ9', 'T1_has_#LVRRYPV', 'T2_has_#LVRRYPV', 'T1_has_#LYGVU8C', 'T2_has_#LYGVU8C', 'T1_has_#LYR0Q9C', 'T2_has_#LYR0Q9C', 'T1_has_#P02J299GU', 'T2_has_#P02J299GU', 'T1_has_#P0LYVV8J', 'T2_has_#P0LYVV8J', 'T1_has_#P0Y8JGL0U', 'T2_has_#P0Y8JGL0U', 'T1_has_#P0YCRUCJY', 'T2_has_#P0YCRUCJY', 'T1_has_#P20V908QU', 'T2_has_#P20V908QU', 'T1_has_#P22GLVULL', 'T2_has_#P22GLVULL', 'T1_has_#P22U8228G', 'T2_has_#P22U8228G', 'T1_has_#P2808PRC', 'T2_has_#P2808PRC', 'T1_has_#P2P0VR0G', 'T2_has_#P2P0VR0G', 'T1_has_#P2PRC2YQQ', 'T2_has_#P2PRC2YQQ', 'T1_has_#P8Y2RQ2RL', 'T2_has_#P8Y2RQ2RL', 'T1_has_#P90GVUV80', 'T2_has_#P90GVUV80', 'T1_has_#P90RJQ8C', 'T2_has_#P90RJQ8C', 'T1_has_#P92R9L28G', 'T2_has_#P92R9L28G', 'T1_has_#P9G88YY9J', 'T2_has_#P9G88YY9J', 'T1_has_#P9QYU0QYR', 'T2_has_#P9QYU0QYR', 'T1_has_#PCJL8Q82U', 'T2_has_#PCJL8Q82U', 'T1_has_#PCPRPJV', 'T2_has_#PCPRPJV', 'T1_has_#PCUL0C98P', 'T2_has_#PCUL0C98P', 'T1_has_#PG0JYVQPQ', 'T2_has_#PG0JYVQPQ', 'T1_has_#PG8YCGGCV', 'T2_has_#PG8YCGGCV', 'T1_has_#PGGJQP2PQ', 'T2_has_#PGGJQP2PQ', 'T1_has_#PGJRY8QJ0', 'T2_has_#PGJRY8QJ0', 'T1_has_#PGL2UL0CR', 'T2_has_#PGL2UL0CR', 'T1_has_#PGYCUCUYG', 'T2_has_#PGYCUCUYG', 'T1_has_#PJGGV2Q80', 'T2_has_#PJGGV2Q80', 'T1_has_#PJQG89R2J', 'T2_has_#PJQG89R2J', 'T1_has_#PLLRJC2V', 'T2_has_#PLLRJC2V', 'T1_has_#PLQ9U80G2', 'T2_has_#PLQ9U80G2', 'T1_has_#PLV89CGP', 'T2_has_#PLV89CGP', 'T1_has_#PLVYRR929', 'T2_has_#PLVYRR929', 'T1_has_#PPG8C2P2', 'T2_has_#PPG8C2P2', 'T1_has_#PPPPJL88R', 'T2_has_#PPPPJL88R', 'T1_has_#PPQ8VV2', 'T2_has_#PPQ8VV2', 'T1_has_#PQ9C9RQ', 'T2_has_#PQ9C9RQ', 'T1_has_#PR0P8QVQ', 'T2_has_#PR0P8QVQ', 'T1_has_#PR9U2JL', 'T2_has_#PR9U2JL', 'T1_has_#PU20LUCQG', 'T2_has_#PU20LUCQG', 'T1_has_#PU8RPR29G', 'T2_has_#PU8RPR29G', 'T1_has_#PU8VPU2GV', 'T2_has_#PU8VPU2GV', 'T1_has_#PUPCGJQQR', 'T2_has_#PUPCGJQQR', 'T1_has_#PURJRYR29', 'T2_has_#PURJRYR29', 'T1_has_#PUYRPJ2VC', 'T2_has_#PUYRPJ2VC', 'T1_has_#PVQ9QUY', 'T2_has_#PVQ9QUY', 'T1_has_#PVRLUJU', 'T2_has_#PVRLUJU', 'T1_has_#PY2RR0UCQ', 'T2_has_#PY2RR0UCQ', 'T1_has_#Q22ULY9JY', 'T2_has_#Q22ULY9JY', 'T1_has_#Q2VCLG9Y9', 'T2_has_#Q2VCLG9Y9', 'T1_has_#Q2VQVC9', 'T2_has_#Q2VQVC9', 'T1_has_#Q2Y2220UG', 'T2_has_#Q2Y2220UG', 'T1_has_#Q808R2CV', 'T2_has_#Q808R2CV', 'T1_has_#Q9LPQYRU9', 'T2_has_#Q9LPQYRU9', 'T1_has_#QCC9RVYQQ', 'T2_has_#QCC9RVYQQ', 'T1_has_#QJQ0YPV', 'T2_has_#QJQ0YPV', 'T1_has_#QJULVGU', 'T2_has_#QJULVGU', 'T1_has_#QL8J82G8', 'T2_has_#QL8J82G8', 'T1_has_#QLCJGQUP', 'T2_has_#QLCJGQUP', 'T1_has_#QLQQUUU0', 'T2_has_#QLQQUUU0', 'T1_has_#QLVU09CY', 'T2_has_#QLVU09CY', 'T1_has_#QPVJYY8JQ', 'T2_has_#QPVJYY8JQ', 'T1_has_#QQJLG9P2Q', 'T2_has_#QQJLG9P2Q', 'T1_has_#QUG9RP9', 'T2_has_#QUG9RP9', 'T1_has_#QURVLPG', 'T2_has_#QURVLPG', 'T1_has_#QUYCVC2', 'T2_has_#QUYCVC2', 'T1_has_#QVULGUV', 'T2_has_#QVULGUV', 'T1_has_#R0PPJ9PV', 'T2_has_#R0PPJ9PV', 'T1_has_#R0VQ82GU', 'T2_has_#R0VQ82GU', 'T1_has_#R2LR2QLG', 'T2_has_#R2LR2QLG', 'T1_has_#R8Q0C2P2', 'T2_has_#R8Q0C2P2', 'T1_has_#R9C0J2P2', 'T2_has_#R9C0J2P2', 'T1_has_#R9CCLP8Q', 'T2_has_#R9CCLP8Q', 'T1_has_#RCYQUJU0', 'T2_has_#RCYQUJU0', 'T1_has_#RGUGP9R', 'T2_has_#RGUGP9R', 'T1_has_#RL02R0GR', 'T2_has_#RL02R0GR', 'T1_has_#RPUYRP8V', 'T2_has_#RPUYRP8V', 'T1_has_#RV9JGVYL', 'T2_has_#RV9JGVYL', 'T1_has_#RVL0RPR9', 'T2_has_#RVL0RPR9', 'T1_has_#U0JVLJGG', 'T2_has_#U0JVLJGG', 'T1_has_#U9GC8G02', 'T2_has_#U9GC8G02', 'T1_has_#UJ2Y90PV', 'T2_has_#UJ2Y90PV', 'T1_has_#UR2UCYQR', 'T2_has_#UR2UCYQR', 'T1_has_#UR2UL8YR', 'T2_has_#UR2UL8YR', 'T1_has_#URV8JPY', 'T2_has_#URV8JPY', 'T1_has_#UUU0V8CG', 'T2_has_#UUU0V8CG', 'T1_has_#V0QQCV80', 'T2_has_#V0QQCV80', 'T1_has_#V89Y2GP0', 'T2_has_#V89Y2GP0', 'T1_has_#V8P2CCY', 'T2_has_#V8P2CCY', 'T1_has_#VGVG2R0V', 'T2_has_#VGVG2R0V', 'T1_has_#VJ2QCPV9', 'T2_has_#VJ2QCPV9', 'T1_has_#VJUQ0Y', 'T2_has_#VJUQ0Y', 'T1_has_#VPVLG2', 'T2_has_#VPVLG2', 'T1_has_#VYGUP9Q0', 'T2_has_#VYGUP9Q0', 'T1_has_#Y0VGCP2QU', 'T2_has_#Y0VGCP2QU', 'T1_has_#Y2VUV8UYV', 'T2_has_#Y2VUV8UYV', 'T1_has_#Y8PLP8VY', 'T2_has_#Y8PLP8VY', 'T1_has_#Y8PLRJR', 'T2_has_#Y8PLRJR', 'T1_has_#Y9C2GYL9Q', 'T2_has_#Y9C2GYL9Q', 'T1_has_#Y9GCL099J', 'T2_has_#Y9GCL099J', 'T1_has_#Y9R8GCCQ', 'T2_has_#Y9R8GCCQ', 'T1_has_#Y9YCGLJ9C', 'T2_has_#Y9YCGLJ9C', 'T1_has_#YCUGURU89', 'T2_has_#YCUGURU89', 'T1_has_#YG0LVYRRY', 'T2_has_#YG0LVYRRY', 'T1_has_#YGQ2PQP0R', 'T2_has_#YGQ2PQP0R', 'T1_has_#YGQUQ2QPP', 'T2_has_#YGQUQ2QPP', 'T1_has_#YGQYGCR', 'T2_has_#YGQYGCR', 'T1_has_#YL2LUYYLG', 'T2_has_#YL2LUYYLG', 'T1_has_#YQLP8LP8', 'T2_has_#YQLP8LP8', 'T1_has_#YQUCCJ2', 'T2_has_#YQUCCJ2', 'T1_has_#YQV0JVPV', 'T2_has_#YQV0JVPV', 'T1_has_#YR2Y9JRCC', 'T2_has_#YR2Y9JRCC', 'T1_has_#YRQ8RP0C9', 'T2_has_#YRQ8RP0C9', 'T1_has_#YUYYLVJ', 'T2_has_#YUYYLVJ', 'T1_has_#YVQ0R9QL', 'T2_has_#YVQ0R9QL', 'T1_has_#YVQCUGV9', 'T2_has_#YVQCUGV9']\n",
      "Unordered-set XGBoost accuracy: 0.6067961165048543\n",
      "testing hyperparameter impact\n",
      "   colsample_bytree  learning_rate  max_depth  n_estimators  subsample  \\\n",
      "0               0.8            0.2          5           100        0.8   \n",
      "1               0.8            0.2          7           100        0.8   \n",
      "2               0.8            0.1          7           200        1.0   \n",
      "3               0.8            0.2          5           200        0.8   \n",
      "\n",
      "   accuracy  \n",
      "0  0.629450  \n",
      "1  0.622977  \n",
      "2  0.618123  \n",
      "3  0.618123  \n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "from pandas.errors import PerformanceWarning\n",
    "\n",
    "# turn off only the “highly fragmented” performance warnings\n",
    "warnings.filterwarnings('ignore', category=PerformanceWarning)\n",
    "\n",
    "# 1. Load the CSV again\n",
    "no_draft_df = pd.read_csv('data/brawl_scrim_040325.csv').iloc[:, 2:]\n",
    "\n",
    "# 2. Drop the specified columns\n",
    "drop_cols = [\n",
    "    'Day', 'Hour',\n",
    "    'P1', 'P2', 'P3', 'P4', 'P5', 'P6',\n",
    "    'Brawler 1','Brawler 2','Brawler 3','Brawler 4','Brawler 5','Brawler 6',\n",
    "    # 'Tag 1', 'Tag 2', 'Tag 3', 'Tag 4', 'Tag 5', 'Tag 6',\n",
    "    'Type', 'ISO',\n",
    "    'team 1', 'team 2'\n",
    "]\n",
    "no_draft_df = no_draft_df.drop(drop_cols, axis=1, errors='ignore')\n",
    "\n",
    "# 3. Extract 'ID' so it's not used as a feature or target\n",
    "ids = no_draft_df.pop('ID')\n",
    "\n",
    "# 5. Drop the rare 'draw' rows\n",
    "no_draft_df = no_draft_df[no_draft_df['Team1 Result'] != 'draw']\n",
    "\n",
    "# 6. Map 'victory'->1, 'defeat'->0\n",
    "no_draft_df['Team1 Result'] = no_draft_df['Team1 Result'].map({'victory': 1, 'defeat': 0})\n",
    "\n",
    "# Split train/test data\n",
    "no_draft_train_df, no_draft_test_df = train_test_split(no_draft_df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Check remaining columns\n",
    "print(no_draft_df.columns.tolist())\n",
    "\n",
    "# --- after you've done train/test split ---\n",
    "\n",
    "# Define your slot columns\n",
    "team1 = ['Tag 1', 'Tag 2', 'Tag 3']\n",
    "team2 = ['Tag 4', 'Tag 5', 'Tag 6']\n",
    "\n",
    "# 1. Gather every unique brawler ID in train (so test uses the same set)\n",
    "all_brawlers = pd.unique(\n",
    "    pd.concat([no_draft_train_df[c] for c in team1 + team2], ignore_index=True)\n",
    ")\n",
    "all_brawlers = sorted([b for b in all_brawlers if pd.notna(b)])  # drop NaNs\n",
    "\n",
    "# 2. One‑hot “does this team have brawler X?”\n",
    "for df_ in (no_draft_train_df, no_draft_test_df):\n",
    "    for b in all_brawlers:\n",
    "        df_[f'T1_has_{b}'] = df_[team1].isin([b]).any(axis=1).astype(int)\n",
    "        df_[f'T2_has_{b}'] = df_[team2].isin([b]).any(axis=1).astype(int)\n",
    "    # 3. drop the original slot columns\n",
    "    df_.drop(team1 + team2, axis=1, inplace=True)\n",
    "\n",
    "# 4. (Optional) convert Mode/Map to numeric codes\n",
    "for col in ['Mode','Map']:\n",
    "    no_draft_train_df[col] = no_draft_train_df[col].astype('category').cat.codes\n",
    "    no_draft_test_df[col]  = no_draft_test_df[col].astype('category').cat.codes\n",
    "\n",
    "# 5. Now you can fit XGBoost exactly as before:\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X_train = no_draft_train_df.drop('Team1 Result', axis=1)\n",
    "y_train = no_draft_train_df['Team1 Result']\n",
    "X_test  = no_draft_test_df.drop('Team1 Result', axis=1)\n",
    "y_test  = no_draft_test_df['Team1 Result']\n",
    "\n",
    "#double check training columns\n",
    "print(X_train.columns.tolist())\n",
    "print(X_test.columns.tolist())\n",
    "\n",
    "model = XGBClassifier(eval_metric='logloss', n_jobs=-1)\n",
    "model.fit(X_train, y_train)\n",
    "print(\"Unordered-set XGBoost accuracy:\", accuracy_score(y_test, model.predict(X_test)))\n",
    "\n",
    "print(\"testing hyperparameter impact\")\n",
    "# 3. Loop over all combinations, train & evaluate\n",
    "results = []\n",
    "for params in ParameterGrid(param_grid):\n",
    "    model = XGBClassifier(\n",
    "        tree_method='hist',\n",
    "        enable_categorical=True,\n",
    "        eval_metric='logloss',\n",
    "        n_jobs=-1,\n",
    "        **params\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "    acc = accuracy_score(y_test, preds)\n",
    "    results.append({**params, 'accuracy': acc})\n",
    "\n",
    "# 4. Collect and sort results\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df = results_df.sort_values('accuracy', ascending=False).reset_index(drop=True)\n",
    "\n",
    "# 5. Inspect top performers\n",
    "print(results_df.head(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1dda8dc",
   "metadata": {},
   "source": [
    "Random forest without draft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7c3925f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier 0.6035598705501618\n",
      "HistGradientBoostingClassifier 0.5857605177993528\n",
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "Best params: {'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 30, 'bootstrap': True}\n",
      "Accuracy: 0.6003236245954693\n",
      "ROC AUC: 0.6414828347254928\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.40      0.47       281\n",
      "           1       0.60      0.77      0.68       337\n",
      "\n",
      "    accuracy                           0.60       618\n",
      "   macro avg       0.60      0.58      0.58       618\n",
      "weighted avg       0.60      0.60      0.58       618\n",
      "\n",
      "Confusion Matrix:\n",
      " [[111 170]\n",
      " [ 77 260]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, HistGradientBoostingClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "rf  = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "hgb = HistGradientBoostingClassifier()\n",
    "\n",
    "for model in (rf, hgb):\n",
    "    model.fit(X_train, y_train)\n",
    "    print(model.__class__.__name__,\n",
    "          accuracy_score(y_test, model.predict(X_test)))\n",
    "    \n",
    "# 2. Hyperparameter distribution (no 'auto')\n",
    "param_dist = {\n",
    "    'n_estimators': [5,10, 20, 50, 100, 200, 500],\n",
    "    'max_depth': [None, 5, 10, 20, 30],\n",
    "    'min_samples_split': [2, 3, 4, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4, 8],\n",
    "    'max_features': ['sqrt', 'log2', None],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "# 3. RandomizedSearchCV optimizing ROC AUC\n",
    "rf = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "rand_search = RandomizedSearchCV(\n",
    "    estimator=rf,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=30,\n",
    "    scoring='accuracy', # or 'roc_auc'\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    random_state=42\n",
    ")\n",
    "rand_search.fit(X_train, y_train)\n",
    "\n",
    "# 4. Evaluate on test\n",
    "best_rf = rand_search.best_estimator_\n",
    "y_pred = best_rf.predict(X_test)\n",
    "y_proba = best_rf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"Best params:\", rand_search.best_params_)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"ROC AUC:\", roc_auc_score(y_test, y_proba))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hw5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
